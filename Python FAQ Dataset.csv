Questions,Answers
What is Python?¶,"Python is an interpreted, interactive, object-oriented programming language.  It
incorporates modules, exceptions, dynamic typing, very high level dynamic data
types, and classes.  It supports multiple programming paradigms beyond
object-oriented programming, such as procedural and functional programming.
Python combines remarkable power with very clear syntax. It has interfaces to
many system calls and libraries, as well as to various window systems, and is
extensible in C or C++.  It is also usable as an extension language for
applications that need a programmable interface. Finally, Python is portable:
it runs on many Unix variants including Linux and macOS, and on Windows.
To find out more, start with The Python Tutorial.  The Beginner’s Guide to
Python links to other
introductory tutorials and resources for learning Python.
The Python Software Foundation is an independent non-profit organization that
holds the copyright on Python versions 2.1 and newer.  The PSF’s mission is to
advance open source technology related to the Python programming language and to
publicize the use of Python.  The PSF’s home page is at
https://www.python.org/psf/.
Donations to the PSF are tax-exempt in the US.  If you use Python and find it
helpful, please contribute via the PSF donation page.
You can do anything you want with the source, as long as you leave the
copyrights in and display those copyrights in any documentation about Python
that you produce.  If you honor the copyright rules, it’s OK to use Python for
commercial use, to sell copies of Python in source or binary form (modified or
unmodified), or to sell products that incorporate Python in some form.  We would
still like to know about all commercial use of Python, of course.
See the license page to find further
explanations and the full text of the PSF License.
The Python logo is trademarked, and in certain cases permission is required to
use it.  Consult the Trademark Usage Policy for more information.
Here’s a very brief summary of what started it all, written by Guido van
Rossum:
I had extensive experience with implementing an interpreted language in the
ABC group at CWI, and from working with this group I had learned a lot about
language design.  This is the origin of many Python features, including the
use of indentation for statement grouping and the inclusion of
very-high-level data types (although the details are all different in
Python).
I had a number of gripes about the ABC language, but also liked many of its
features.  It was impossible to extend the ABC language (or its
implementation) to remedy my complaints – in fact its lack of extensibility
was one of its biggest problems.  I had some experience with using Modula-2+
and talked with the designers of Modula-3 and read the Modula-3 report.
Modula-3 is the origin of the syntax and semantics used for exceptions, and
some other Python features.
I was working in the Amoeba distributed operating system group at CWI.  We
needed a better way to do system administration than by writing either C
programs or Bourne shell scripts, since Amoeba had its own system call
interface which wasn’t easily accessible from the Bourne shell.  My
experience with error handling in Amoeba made me acutely aware of the
importance of exceptions as a programming language feature.
It occurred to me that a scripting language with a syntax like ABC but with
access to the Amoeba system calls would fill the need.  I realized that it
would be foolish to write an Amoeba-specific language, so I decided that I
needed a language that was generally extensible.
During the 1989 Christmas holidays, I had a lot of time on my hand, so I
decided to give it a try.  During the next year, while still mostly working
on it in my own time, Python was used in the Amoeba project with increasing
success, and the feedback from colleagues made me add many early
improvements.
In February 1991, after just over a year of development, I decided to post to
USENET.  The rest is in the Misc/HISTORY file.
Python is a high-level general-purpose programming language that can be applied
to many different classes of problems.
The language comes with a large standard library that covers areas such as
string processing (regular expressions, Unicode, calculating differences between
files), internet protocols (HTTP, FTP, SMTP, XML-RPC, POP, IMAP),
software engineering (unit testing, logging, profiling, parsing
Python code), and operating system interfaces (system calls, filesystems, TCP/IP
sockets).  Look at the table of contents for The Python Standard Library to get an idea
of what’s available.  A wide variety of third-party extensions are also
available.  Consult the Python Package Index to
find packages of interest to you.
Python versions are numbered “A.B.C” or “A.B”:
A is the major version number – it is only incremented for really major
changes in the language.
B is the minor version number – it is incremented for less earth-shattering
changes.
C is the micro version number – it is incremented for each bugfix release.
Not all releases are bugfix releases.  In the run-up to a new feature release, a
series of development releases are made, denoted as alpha, beta, or release
candidate.  Alphas are early releases in which interfaces aren’t yet finalized;
it’s not unexpected to see an interface change between two alpha releases.
Betas are more stable, preserving existing interfaces but possibly adding new
modules, and release candidates are frozen, making no changes except as needed
to fix critical bugs.
Alpha, beta and release candidate versions have an additional suffix:
The suffix for an alpha version is “aN” for some small number N.
The suffix for a beta version is “bN” for some small number N.
The suffix for a release candidate version is “rcN” for some small number N.
In other words, all versions labeled 2.0aN precede the versions labeled
2.0bN, which precede versions labeled 2.0rcN, and those precede 2.0.
You may also find version numbers with a “+” suffix, e.g. “2.2+”.  These are
unreleased versions, built directly from the CPython development repository.  In
practice, after a final minor release is made, the version is incremented to the
next minor version, which becomes the “a0” version, e.g. “2.4a0”.
See the Developer’s Guide
for more information about the development cycle, and
PEP 387 to learn more about Python’s backward compatibility policy.  See also
the documentation for sys.version, sys.hexversion, and
sys.version_info.
The latest Python source distribution is always available from python.org, at
https://www.python.org/downloads/.  The latest development sources can be obtained
at https://github.com/python/cpython/.
The source distribution is a gzipped tar file containing the complete C source,
Sphinx-formatted documentation, Python library modules, example programs, and
several useful pieces of freely distributable software.  The source will compile
and run out of the box on most UNIX platforms.
Consult the Getting Started section of the Python Developer’s Guide for more
information on getting the source code and compiling it.
The standard documentation for the current stable version of Python is available
at https://docs.python.org/3/.  PDF, plain text, and downloadable HTML versions are
also available at https://docs.python.org/3/download.html.
The documentation is written in reStructuredText and processed by the Sphinx
documentation tool.  The reStructuredText source for
the documentation is part of the Python source distribution.
There are numerous tutorials and books available.  The standard documentation
includes The Python Tutorial.
Consult the Beginner’s Guide to
find information for beginning Python programmers, including lists of tutorials.
There is a newsgroup, comp.lang.python, and a mailing list,
python-list.  The
newsgroup and mailing list are gatewayed into each other – if you can read news
it’s unnecessary to subscribe to the mailing list.
comp.lang.python is high-traffic, receiving hundreds of postings
every day, and Usenet readers are often more able to cope with this volume.
Announcements of new software releases and events can be found in
comp.lang.python.announce, a low-traffic moderated list that receives about five
postings per day.  It’s available as the python-announce mailing list.
More info about other mailing lists and newsgroups
can be found at https://www.python.org/community/lists/.
Alpha and beta releases are available from https://www.python.org/downloads/.  All
releases are announced on the comp.lang.python and comp.lang.python.announce
newsgroups and on the Python home page at https://www.python.org/; an RSS feed of
news is available.
You can also access the development version of Python through Git.  See
The Python Developer’s Guide for details.
To report a bug or submit a patch, use the issue tracker at
https://github.com/python/cpython/issues.
For more information on how Python is developed, consult the Python Developer’s
Guide.
It’s probably best to cite your favorite book about Python.
The very first article about Python was
written in 1991 and is now quite outdated.
Guido van Rossum and Jelke de Boer, “Interactively Testing Remote Servers
Using the Python Programming Language”, CWI Quarterly, Volume 4, Issue 4
(December 1991), Amsterdam, pp 283–303.
Yes, there are many, and more are being published.  See the python.org wiki at
https://wiki.python.org/moin/PythonBooks for a list.
You can also search online bookstores for “Python” and filter out the Monty
Python references; or perhaps search for “Python” and “language”.
The Python project’s infrastructure is located all over the world and is managed
by the Python Infrastructure Team. Details here.
When he began implementing Python, Guido van Rossum was also reading the
published scripts from “Monty Python’s Flying Circus”, a BBC comedy series from the 1970s.  Van Rossum
thought he needed a name that was short, unique, and slightly mysterious, so he
decided to call the language Python.
No, but it helps.  :)"
What is Python?¶,"Python is an interpreted, interactive, object-oriented programming language.  It
incorporates modules, exceptions, dynamic typing, very high level dynamic data
types, and classes.  It supports multiple programming paradigms beyond
object-oriented programming, such as procedural and functional programming.
Python combines remarkable power with very clear syntax. It has interfaces to
many system calls and libraries, as well as to various window systems, and is
extensible in C or C++.  It is also usable as an extension language for
applications that need a programmable interface. Finally, Python is portable:
it runs on many Unix variants including Linux and macOS, and on Windows.
To find out more, start with The Python Tutorial.  The Beginner’s Guide to
Python links to other
introductory tutorials and resources for learning Python."
What is the Python Software Foundation?¶,"The Python Software Foundation is an independent non-profit organization that
holds the copyright on Python versions 2.1 and newer.  The PSF’s mission is to
advance open source technology related to the Python programming language and to
publicize the use of Python.  The PSF’s home page is at
https://www.python.org/psf/.
Donations to the PSF are tax-exempt in the US.  If you use Python and find it
helpful, please contribute via the PSF donation page."
Are there copyright restrictions on the use of Python?¶,"You can do anything you want with the source, as long as you leave the
copyrights in and display those copyrights in any documentation about Python
that you produce.  If you honor the copyright rules, it’s OK to use Python for
commercial use, to sell copies of Python in source or binary form (modified or
unmodified), or to sell products that incorporate Python in some form.  We would
still like to know about all commercial use of Python, of course.
See the license page to find further
explanations and the full text of the PSF License.
The Python logo is trademarked, and in certain cases permission is required to
use it.  Consult the Trademark Usage Policy for more information."
Why was Python created in the first place?¶,"Here’s a very brief summary of what started it all, written by Guido van
Rossum:
I had extensive experience with implementing an interpreted language in the
ABC group at CWI, and from working with this group I had learned a lot about
language design.  This is the origin of many Python features, including the
use of indentation for statement grouping and the inclusion of
very-high-level data types (although the details are all different in
Python).
I had a number of gripes about the ABC language, but also liked many of its
features.  It was impossible to extend the ABC language (or its
implementation) to remedy my complaints – in fact its lack of extensibility
was one of its biggest problems.  I had some experience with using Modula-2+
and talked with the designers of Modula-3 and read the Modula-3 report.
Modula-3 is the origin of the syntax and semantics used for exceptions, and
some other Python features.
I was working in the Amoeba distributed operating system group at CWI.  We
needed a better way to do system administration than by writing either C
programs or Bourne shell scripts, since Amoeba had its own system call
interface which wasn’t easily accessible from the Bourne shell.  My
experience with error handling in Amoeba made me acutely aware of the
importance of exceptions as a programming language feature.
It occurred to me that a scripting language with a syntax like ABC but with
access to the Amoeba system calls would fill the need.  I realized that it
would be foolish to write an Amoeba-specific language, so I decided that I
needed a language that was generally extensible.
During the 1989 Christmas holidays, I had a lot of time on my hand, so I
decided to give it a try.  During the next year, while still mostly working
on it in my own time, Python was used in the Amoeba project with increasing
success, and the feedback from colleagues made me add many early
improvements.
In February 1991, after just over a year of development, I decided to post to
USENET.  The rest is in the Misc/HISTORY file."
What is Python good for?¶,"Python is a high-level general-purpose programming language that can be applied
to many different classes of problems.
The language comes with a large standard library that covers areas such as
string processing (regular expressions, Unicode, calculating differences between
files), internet protocols (HTTP, FTP, SMTP, XML-RPC, POP, IMAP),
software engineering (unit testing, logging, profiling, parsing
Python code), and operating system interfaces (system calls, filesystems, TCP/IP
sockets).  Look at the table of contents for The Python Standard Library to get an idea
of what’s available.  A wide variety of third-party extensions are also
available.  Consult the Python Package Index to
find packages of interest to you."
How does the Python version numbering scheme work?¶,"Python versions are numbered “A.B.C” or “A.B”:
A is the major version number – it is only incremented for really major
changes in the language.
B is the minor version number – it is incremented for less earth-shattering
changes.
C is the micro version number – it is incremented for each bugfix release.
Not all releases are bugfix releases.  In the run-up to a new feature release, a
series of development releases are made, denoted as alpha, beta, or release
candidate.  Alphas are early releases in which interfaces aren’t yet finalized;
it’s not unexpected to see an interface change between two alpha releases.
Betas are more stable, preserving existing interfaces but possibly adding new
modules, and release candidates are frozen, making no changes except as needed
to fix critical bugs.
Alpha, beta and release candidate versions have an additional suffix:
The suffix for an alpha version is “aN” for some small number N.
The suffix for a beta version is “bN” for some small number N.
The suffix for a release candidate version is “rcN” for some small number N.
In other words, all versions labeled 2.0aN precede the versions labeled
2.0bN, which precede versions labeled 2.0rcN, and those precede 2.0.
You may also find version numbers with a “+” suffix, e.g. “2.2+”.  These are
unreleased versions, built directly from the CPython development repository.  In
practice, after a final minor release is made, the version is incremented to the
next minor version, which becomes the “a0” version, e.g. “2.4a0”.
See the Developer’s Guide
for more information about the development cycle, and
PEP 387 to learn more about Python’s backward compatibility policy.  See also
the documentation for sys.version, sys.hexversion, and
sys.version_info."
How do I obtain a copy of the Python source?¶,"The latest Python source distribution is always available from python.org, at
https://www.python.org/downloads/.  The latest development sources can be obtained
at https://github.com/python/cpython/.
The source distribution is a gzipped tar file containing the complete C source,
Sphinx-formatted documentation, Python library modules, example programs, and
several useful pieces of freely distributable software.  The source will compile
and run out of the box on most UNIX platforms.
Consult the Getting Started section of the Python Developer’s Guide for more
information on getting the source code and compiling it."
How do I get documentation on Python?¶,"The standard documentation for the current stable version of Python is available
at https://docs.python.org/3/.  PDF, plain text, and downloadable HTML versions are
also available at https://docs.python.org/3/download.html.
The documentation is written in reStructuredText and processed by the Sphinx
documentation tool.  The reStructuredText source for
the documentation is part of the Python source distribution."
I’ve never programmed before. Is there a Python tutorial?¶,"There are numerous tutorials and books available.  The standard documentation
includes The Python Tutorial.
Consult the Beginner’s Guide to
find information for beginning Python programmers, including lists of tutorials."
Is there a newsgroup or mailing list devoted to Python?¶,"There is a newsgroup, comp.lang.python, and a mailing list,
python-list.  The
newsgroup and mailing list are gatewayed into each other – if you can read news
it’s unnecessary to subscribe to the mailing list.
comp.lang.python is high-traffic, receiving hundreds of postings
every day, and Usenet readers are often more able to cope with this volume.
Announcements of new software releases and events can be found in
comp.lang.python.announce, a low-traffic moderated list that receives about five
postings per day.  It’s available as the python-announce mailing list.
More info about other mailing lists and newsgroups
can be found at https://www.python.org/community/lists/."
How do I get a beta test version of Python?¶,"Alpha and beta releases are available from https://www.python.org/downloads/.  All
releases are announced on the comp.lang.python and comp.lang.python.announce
newsgroups and on the Python home page at https://www.python.org/; an RSS feed of
news is available.
You can also access the development version of Python through Git.  See
The Python Developer’s Guide for details."
How do I submit bug reports and patches for Python?¶,"To report a bug or submit a patch, use the issue tracker at
https://github.com/python/cpython/issues.
For more information on how Python is developed, consult the Python Developer’s
Guide."
Are there any published articles about Python that I can reference?¶,"It’s probably best to cite your favorite book about Python.
The very first article about Python was
written in 1991 and is now quite outdated.
Guido van Rossum and Jelke de Boer, “Interactively Testing Remote Servers
Using the Python Programming Language”, CWI Quarterly, Volume 4, Issue 4
(December 1991), Amsterdam, pp 283–303."
Are there any books on Python?¶,"Yes, there are many, and more are being published.  See the python.org wiki at
https://wiki.python.org/moin/PythonBooks for a list.
You can also search online bookstores for “Python” and filter out the Monty
Python references; or perhaps search for “Python” and “language”."
Where in the world is www.python.org located?¶,"The Python project’s infrastructure is located all over the world and is managed
by the Python Infrastructure Team. Details here."
Why is it called Python?¶,"When he began implementing Python, Guido van Rossum was also reading the
published scripts from “Monty Python’s Flying Circus”, a BBC comedy series from the 1970s.  Van Rossum
thought he needed a name that was short, unique, and slightly mysterious, so he
decided to call the language Python."
Do I have to like “Monty Python’s Flying Circus”?¶,"No, but it helps.  :)"
How stable is Python?¶,"Very stable.  New, stable releases have been coming out roughly every 6 to 18
months since 1991, and this seems likely to continue.  As of version 3.9,
Python will have a new feature release every 12 months (PEP 602).
The developers issue bugfix releases of older versions, so the stability of
existing releases gradually improves.  Bugfix releases, indicated by a third
component of the version number (e.g. 3.5.3, 3.6.2), are managed for stability;
only fixes for known problems are included in a bugfix release, and it’s
guaranteed that interfaces will remain the same throughout a series of bugfix
releases.
The latest stable releases can always be found on the Python download page.  There are two production-ready versions
of Python: 2.x and 3.x. The recommended version is 3.x, which is supported by
most widely used libraries.  Although 2.x is still widely used, it is not
maintained anymore.
There are probably millions of users, though it’s difficult to obtain an exact
count.
Python is available for free download, so there are no sales figures, and it’s
available from many different sites and packaged with many Linux distributions,
so download statistics don’t tell the whole story either.
The comp.lang.python newsgroup is very active, but not all Python users post to
the group or even read it.
See https://www.python.org/about/success for a list of projects that use Python.
Consulting the proceedings for past Python conferences will reveal contributions from many
different companies and organizations.
High-profile Python projects include the Mailman mailing list manager and the Zope application server.  Several Linux distributions, most notably Red Hat, have written part or all of their installer and
system administration software in Python.  Companies that use Python internally
include Google, Yahoo, and Lucasfilm Ltd.
See https://peps.python.org/ for the Python Enhancement Proposals
(PEPs). PEPs are design documents describing a suggested new feature for Python,
providing a concise technical specification and a rationale.  Look for a PEP
titled “Python X.Y Release Schedule”, where X.Y is a version that hasn’t been
publicly released yet.
New development is discussed on the python-dev mailing list.
In general, no.  There are already millions of lines of Python code around the
world, so any change in the language that invalidates more than a very small
fraction of existing programs has to be frowned upon.  Even if you can provide a
conversion program, there’s still the problem of updating all documentation;
many books have been written about Python, and we don’t want to invalidate them
all at a single stroke.
Providing a gradual upgrade path is necessary if a feature has to be changed.
PEP 5 describes the procedure followed for introducing backward-incompatible
changes while minimizing disruption for users.
Yes.
It is still common to start students with a procedural and statically typed
language such as Pascal, C, or a subset of C++ or Java.  Students may be better
served by learning Python as their first language.  Python has a very simple and
consistent syntax and a large standard library and, most importantly, using
Python in a beginning programming course lets students concentrate on important
programming skills such as problem decomposition and data type design.  With
Python, students can be quickly introduced to basic concepts such as loops and
procedures.  They can probably even work with user-defined objects in their very
first course.
For a student who has never programmed before, using a statically typed language
seems unnatural.  It presents additional complexity that the student must master
and slows the pace of the course.  The students are trying to learn to think
like a computer, decompose problems, design consistent interfaces, and
encapsulate data.  While learning to use a statically typed language is
important in the long term, it is not necessarily the best topic to address in
the students’ first programming course.
Many other aspects of Python make it a good first language.  Like Java, Python
has a large standard library so that students can be assigned programming
projects very early in the course that do something.  Assignments aren’t
restricted to the standard four-function calculator and check balancing
programs.  By using the standard library, students can gain the satisfaction of
working on realistic applications as they learn the fundamentals of programming.
Using the standard library also teaches students about code reuse.  Third-party
modules such as PyGame are also helpful in extending the students’ reach.
Python’s interactive interpreter enables students to test language features
while they’re programming.  They can keep a window with the interpreter running
while they enter their program’s source in another window.  If they can’t
remember the methods for a list, they can do something like this:
With the interpreter, documentation is never far from the student as they are
programming.
There are also good IDEs for Python.  IDLE is a cross-platform IDE for Python
that is written in Python using Tkinter.
Emacs users will be happy to know that there is a very good Python mode for
Emacs.  All of these programming environments provide syntax highlighting,
auto-indenting, and access to the interactive interpreter while coding.  Consult
the Python wiki for a full list
of Python editing environments.
If you want to discuss Python’s use in education, you may be interested in
joining the edu-sig mailing list."
How stable is Python?¶,"Very stable.  New, stable releases have been coming out roughly every 6 to 18
months since 1991, and this seems likely to continue.  As of version 3.9,
Python will have a new feature release every 12 months (PEP 602).
The developers issue bugfix releases of older versions, so the stability of
existing releases gradually improves.  Bugfix releases, indicated by a third
component of the version number (e.g. 3.5.3, 3.6.2), are managed for stability;
only fixes for known problems are included in a bugfix release, and it’s
guaranteed that interfaces will remain the same throughout a series of bugfix
releases.
The latest stable releases can always be found on the Python download page.  There are two production-ready versions
of Python: 2.x and 3.x. The recommended version is 3.x, which is supported by
most widely used libraries.  Although 2.x is still widely used, it is not
maintained anymore."
How many people are using Python?¶,"There are probably millions of users, though it’s difficult to obtain an exact
count.
Python is available for free download, so there are no sales figures, and it’s
available from many different sites and packaged with many Linux distributions,
so download statistics don’t tell the whole story either.
The comp.lang.python newsgroup is very active, but not all Python users post to
the group or even read it."
Have any significant projects been done in Python?¶,"See https://www.python.org/about/success for a list of projects that use Python.
Consulting the proceedings for past Python conferences will reveal contributions from many
different companies and organizations.
High-profile Python projects include the Mailman mailing list manager and the Zope application server.  Several Linux distributions, most notably Red Hat, have written part or all of their installer and
system administration software in Python.  Companies that use Python internally
include Google, Yahoo, and Lucasfilm Ltd."
What new developments are expected for Python in the future?¶,"See https://peps.python.org/ for the Python Enhancement Proposals
(PEPs). PEPs are design documents describing a suggested new feature for Python,
providing a concise technical specification and a rationale.  Look for a PEP
titled “Python X.Y Release Schedule”, where X.Y is a version that hasn’t been
publicly released yet.
New development is discussed on the python-dev mailing list."
Is it reasonable to propose incompatible changes to Python?¶,"In general, no.  There are already millions of lines of Python code around the
world, so any change in the language that invalidates more than a very small
fraction of existing programs has to be frowned upon.  Even if you can provide a
conversion program, there’s still the problem of updating all documentation;
many books have been written about Python, and we don’t want to invalidate them
all at a single stroke.
Providing a gradual upgrade path is necessary if a feature has to be changed.
PEP 5 describes the procedure followed for introducing backward-incompatible
changes while minimizing disruption for users."
Is Python a good language for beginning programmers?¶,"Yes.
It is still common to start students with a procedural and statically typed
language such as Pascal, C, or a subset of C++ or Java.  Students may be better
served by learning Python as their first language.  Python has a very simple and
consistent syntax and a large standard library and, most importantly, using
Python in a beginning programming course lets students concentrate on important
programming skills such as problem decomposition and data type design.  With
Python, students can be quickly introduced to basic concepts such as loops and
procedures.  They can probably even work with user-defined objects in their very
first course.
For a student who has never programmed before, using a statically typed language
seems unnatural.  It presents additional complexity that the student must master
and slows the pace of the course.  The students are trying to learn to think
like a computer, decompose problems, design consistent interfaces, and
encapsulate data.  While learning to use a statically typed language is
important in the long term, it is not necessarily the best topic to address in
the students’ first programming course.
Many other aspects of Python make it a good first language.  Like Java, Python
has a large standard library so that students can be assigned programming
projects very early in the course that do something.  Assignments aren’t
restricted to the standard four-function calculator and check balancing
programs.  By using the standard library, students can gain the satisfaction of
working on realistic applications as they learn the fundamentals of programming.
Using the standard library also teaches students about code reuse.  Third-party
modules such as PyGame are also helpful in extending the students’ reach.
Python’s interactive interpreter enables students to test language features
while they’re programming.  They can keep a window with the interpreter running
while they enter their program’s source in another window.  If they can’t
remember the methods for a list, they can do something like this:
With the interpreter, documentation is never far from the student as they are
programming.
There are also good IDEs for Python.  IDLE is a cross-platform IDE for Python
that is written in Python using Tkinter.
Emacs users will be happy to know that there is a very good Python mode for
Emacs.  All of these programming environments provide syntax highlighting,
auto-indenting, and access to the interactive interpreter while coding.  Consult
the Python wiki for a full list
of Python editing environments.
If you want to discuss Python’s use in education, you may be interested in
joining the edu-sig mailing list."
"Is there a source code level debugger with breakpoints, single-stepping, etc.?¶","Yes.
Several debuggers for Python are described below, and the built-in function
breakpoint() allows you to drop into any of them.
The pdb module is a simple but adequate console-mode debugger for Python. It is
part of the standard Python library, and is documented in the Library
Reference Manual. You can also write your own debugger by using the code
for pdb as an example.
The IDLE interactive development environment, which is part of the standard
Python distribution (normally available as
Tools/scripts/idle3),
includes a graphical debugger.
PythonWin is a Python IDE that includes a GUI debugger based on pdb.  The
PythonWin debugger colors breakpoints and has quite a few cool features such as
debugging non-PythonWin programs.  PythonWin is available as part of
pywin32 project and
as a part of the
ActivePython distribution.
Eric is an IDE built on PyQt
and the Scintilla editing component.
trepan3k is a gdb-like debugger.
Visual Studio Code is an IDE with debugging
tools that integrates with version-control software.
There are a number of commercial Python IDEs that include graphical debuggers.
They include:
Wing IDE
Komodo IDE
PyCharm
Yes.
Pylint and
Pyflakes do basic checking that will
help you catch bugs sooner.
Static type checkers such as Mypy,
Pyre, and
Pytype can check type hints in Python
source code.
You don’t need the ability to compile Python to C code if all you want is a
stand-alone program that users can download and run without having to install
the Python distribution first.  There are a number of tools that determine the
set of modules required by a program and bind these modules together with a
Python binary to produce a single executable.
One is to use the freeze tool, which is included in the Python source tree as
Tools/freeze.
It converts Python byte code to C arrays; with a C compiler you can
embed all your modules into a new program, which is then linked with the
standard Python modules.
It works by scanning your source recursively for import statements (in both
forms) and looking for the modules in the standard Python path as well as in the
source directory (for built-in modules).  It then turns the bytecode for modules
written in Python into C code (array initializers that can be turned into code
objects using the marshal module) and creates a custom-made config file that
only contains those built-in modules which are actually used in the program.  It
then compiles the generated C code and links it with the rest of the Python
interpreter to form a self-contained binary which acts exactly like your script.
The following packages can help with the creation of console and GUI
executables:
Nuitka (Cross-platform)
PyInstaller (Cross-platform)
PyOxidizer (Cross-platform)
cx_Freeze (Cross-platform)
py2app (macOS only)
py2exe (Windows only)
Yes.  The coding style required for standard library modules is documented as
PEP 8."
"Is there a source code level debugger with breakpoints, single-stepping, etc.?¶","Yes.
Several debuggers for Python are described below, and the built-in function
breakpoint() allows you to drop into any of them.
The pdb module is a simple but adequate console-mode debugger for Python. It is
part of the standard Python library, and is documented in the Library
Reference Manual. You can also write your own debugger by using the code
for pdb as an example.
The IDLE interactive development environment, which is part of the standard
Python distribution (normally available as
Tools/scripts/idle3),
includes a graphical debugger.
PythonWin is a Python IDE that includes a GUI debugger based on pdb.  The
PythonWin debugger colors breakpoints and has quite a few cool features such as
debugging non-PythonWin programs.  PythonWin is available as part of
pywin32 project and
as a part of the
ActivePython distribution.
Eric is an IDE built on PyQt
and the Scintilla editing component.
trepan3k is a gdb-like debugger.
Visual Studio Code is an IDE with debugging
tools that integrates with version-control software.
There are a number of commercial Python IDEs that include graphical debuggers.
They include:
Wing IDE
Komodo IDE
PyCharm"
Are there tools to help find bugs or perform static analysis?¶,"Yes.
Pylint and
Pyflakes do basic checking that will
help you catch bugs sooner.
Static type checkers such as Mypy,
Pyre, and
Pytype can check type hints in Python
source code."
How can I create a stand-alone binary from a Python script?¶,"You don’t need the ability to compile Python to C code if all you want is a
stand-alone program that users can download and run without having to install
the Python distribution first.  There are a number of tools that determine the
set of modules required by a program and bind these modules together with a
Python binary to produce a single executable.
One is to use the freeze tool, which is included in the Python source tree as
Tools/freeze.
It converts Python byte code to C arrays; with a C compiler you can
embed all your modules into a new program, which is then linked with the
standard Python modules.
It works by scanning your source recursively for import statements (in both
forms) and looking for the modules in the standard Python path as well as in the
source directory (for built-in modules).  It then turns the bytecode for modules
written in Python into C code (array initializers that can be turned into code
objects using the marshal module) and creates a custom-made config file that
only contains those built-in modules which are actually used in the program.  It
then compiles the generated C code and links it with the rest of the Python
interpreter to form a self-contained binary which acts exactly like your script.
The following packages can help with the creation of console and GUI
executables:
Nuitka (Cross-platform)
PyInstaller (Cross-platform)
PyOxidizer (Cross-platform)
cx_Freeze (Cross-platform)
py2app (macOS only)
py2exe (Windows only)"
Are there coding standards or a style guide for Python programs?¶,"Yes.  The coding style required for standard library modules is documented as
PEP 8."
Why am I getting an UnboundLocalError when the variable has a value?¶,"It can be a surprise to get the UnboundLocalError in previously working
code when it is modified by adding an assignment statement somewhere in
the body of a function.
This code:
works, but this code:
results in an UnboundLocalError:
This is because when you make an assignment to a variable in a scope, that
variable becomes local to that scope and shadows any similarly named variable
in the outer scope.  Since the last statement in foo assigns a new value to
x, the compiler recognizes it as a local variable.  Consequently when the
earlier print(x) attempts to print the uninitialized local variable and
an error results.
In the example above you can access the outer scope variable by declaring it
global:
This explicit declaration is required in order to remind you that (unlike the
superficially analogous situation with class and instance variables) you are
actually modifying the value of the variable in the outer scope:
You can do a similar thing in a nested scope using the nonlocal
keyword:
In Python, variables that are only referenced inside a function are implicitly
global.  If a variable is assigned a value anywhere within the function’s body,
it’s assumed to be a local unless explicitly declared as global.
Though a bit surprising at first, a moment’s consideration explains this.  On
one hand, requiring global for assigned variables provides a bar
against unintended side-effects.  On the other hand, if global was required
for all global references, you’d be using global all the time.  You’d have
to declare as global every reference to a built-in function or to a component of
an imported module.  This clutter would defeat the usefulness of the global
declaration for identifying side-effects.
Assume you use a for loop to define a few different lambdas (or even plain
functions), e.g.:
This gives you a list that contains 5 lambdas that calculate x**2.  You
might expect that, when called, they would return, respectively, 0, 1,
4, 9, and 16.  However, when you actually try you will see that
they all return 16:
This happens because x is not local to the lambdas, but is defined in
the outer scope, and it is accessed when the lambda is called — not when it
is defined.  At the end of the loop, the value of x is 4, so all the
functions now return 4**2, i.e. 16.  You can also verify this by
changing the value of x and see how the results of the lambdas change:
In order to avoid this, you need to save the values in variables local to the
lambdas, so that they don’t rely on the value of the global x:
Here, n=x creates a new variable n local to the lambda and computed
when the lambda is defined so that it has the same value that x had at
that point in the loop.  This means that the value of n will be 0
in the first lambda, 1 in the second, 2 in the third, and so on.
Therefore each lambda will now return the correct result:
Note that this behaviour is not peculiar to lambdas, but applies to regular
functions too.
The canonical way to share information across modules within a single program is
to create a special module (often called config or cfg).  Just import the config
module in all modules of your application; the module then becomes available as
a global name.  Because there is only one instance of each module, any changes
made to the module object get reflected everywhere.  For example:
config.py:
mod.py:
main.py:
Note that using a module is also the basis for implementing the singleton design
pattern, for the same reason.
In general, don’t use from modulename import *.  Doing so clutters the
importer’s namespace, and makes it much harder for linters to detect undefined
names.
Import modules at the top of a file.  Doing so makes it clear what other modules
your code requires and avoids questions of whether the module name is in scope.
Using one import per line makes it easy to add and delete module imports, but
using multiple imports per line uses less screen space.
It’s good practice if you import modules in the following order:
standard library modules – e.g. sys, os, argparse, re
third-party library modules (anything installed in Python’s site-packages
directory) – e.g. dateutil, requests, PIL.Image
locally developed modules
It is sometimes necessary to move imports to a function or class to avoid
problems with circular imports.  Gordon McMillan says:
Circular imports are fine where both modules use the “import <module>” form
of import.  They fail when the 2nd module wants to grab a name out of the
first (“from module import name”) and the import is at the top level.  That’s
because names in the 1st are not yet available, because the first module is
busy importing the 2nd.
In this case, if the second module is only used in one function, then the import
can easily be moved into that function.  By the time the import is called, the
first module will have finished initializing, and the second module can do its
import.
It may also be necessary to move imports out of the top level of code if some of
the modules are platform-specific.  In that case, it may not even be possible to
import all of the modules at the top of the file.  In this case, importing the
correct modules in the corresponding platform-specific code is a good option.
Only move imports into a local scope, such as inside a function definition, if
it’s necessary to solve a problem such as avoiding a circular import or are
trying to reduce the initialization time of a module.  This technique is
especially helpful if many of the imports are unnecessary depending on how the
program executes.  You may also want to move imports into a function if the
modules are only ever used in that function.  Note that loading a module the
first time may be expensive because of the one time initialization of the
module, but loading a module multiple times is virtually free, costing only a
couple of dictionary lookups.  Even if the module name has gone out of scope,
the module is probably available in sys.modules.
This type of bug commonly bites neophyte programmers.  Consider this function:
The first time you call this function, mydict contains a single item.  The
second time, mydict contains two items because when foo() begins
executing, mydict starts out with an item already in it.
It is often expected that a function call creates new objects for default
values. This is not what happens. Default values are created exactly once, when
the function is defined.  If that object is changed, like the dictionary in this
example, subsequent calls to the function will refer to this changed object.
By definition, immutable objects such as numbers, strings, tuples, and None,
are safe from change. Changes to mutable objects such as dictionaries, lists,
and class instances can lead to confusion.
Because of this feature, it is good programming practice to not use mutable
objects as default values.  Instead, use None as the default value and
inside the function, check if the parameter is None and create a new
list/dictionary/whatever if it is.  For example, don’t write:
but:
This feature can be useful.  When you have a function that’s time-consuming to
compute, a common technique is to cache the parameters and the resulting value
of each call to the function, and return the cached value if the same value is
requested again.  This is called “memoizing”, and can be implemented like this:
You could use a global variable containing a dictionary instead of the default
value; it’s a matter of taste.
Collect the arguments using the * and ** specifiers in the function’s
parameter list; this gives you the positional arguments as a tuple and the
keyword arguments as a dictionary.  You can then pass these arguments when
calling another function by using * and **:
Parameters are defined by the names that appear in a
function definition, whereas arguments are the values
actually passed to a function when calling it.  Parameters define what
kind of arguments a function can accept.  For
example, given the function definition:
foo, bar and kwargs are parameters of func.  However, when calling
func, for example:
the values 42, 314, and somevar are arguments.
If you wrote code like:
you might be wondering why appending an element to y changed x too.
There are two factors that produce this result:
Variables are simply names that refer to objects.  Doing y = x doesn’t
create a copy of the list – it creates a new variable y that refers to
the same object x refers to.  This means that there is only one object
(the list), and both x and y refer to it.
Lists are mutable, which means that you can change their content.
After the call to append(), the content of the mutable object has
changed from [] to [10].  Since both the variables refer to the same
object, using either name accesses the modified value [10].
If we instead assign an immutable object to x:
we can see that in this case x and y are not equal anymore.  This is
because integers are immutable, and when we do x = x + 1 we are not
mutating the int 5 by incrementing its value; instead, we are creating a
new object (the int 6) and assigning it to x (that is, changing which
object x refers to).  After this assignment we have two objects (the ints
6 and 5) and two variables that refer to them (x now refers to
6 but y still refers to 5).
Some operations (for example y.append(10) and y.sort()) mutate the
object, whereas superficially similar operations (for example y = y + [10]
and sorted(y)) create a new object.  In general in Python (and in all cases
in the standard library) a method that mutates an object will return None
to help avoid getting the two types of operations confused.  So if you
mistakenly write y.sort() thinking it will give you a sorted copy of y,
you’ll instead end up with None, which will likely cause your program to
generate an easily diagnosed error.
However, there is one class of operations where the same operation sometimes
has different behaviors with different types:  the augmented assignment
operators.  For example, += mutates lists but not tuples or ints (a_list
+= [1, 2, 3] is equivalent to a_list.extend([1, 2, 3]) and mutates
a_list, whereas some_tuple += (1, 2, 3) and some_int += 1 create
new objects).
In other words:
If we have a mutable object (list, dict, set,
etc.), we can use some specific operations to mutate it and all the variables
that refer to it will see the change.
If we have an immutable object (str, int, tuple,
etc.), all the variables that refer to it will always see the same value,
but operations that transform that value into a new value always return a new
object.
If you want to know if two variables refer to the same object or not, you can
use the is operator, or the built-in function id().
Remember that arguments are passed by assignment in Python.  Since assignment
just creates references to objects, there’s no alias between an argument name in
the caller and callee, and so no call-by-reference per se.  You can achieve the
desired effect in a number of ways.
By returning a tuple of the results:
This is almost always the clearest solution.
By using global variables.  This isn’t thread-safe, and is not recommended.
By passing a mutable (changeable in-place) object:
By passing in a dictionary that gets mutated:
Or bundle up values in a class instance:
There’s almost never a good reason to get this complicated.
Your best choice is to return a tuple containing the multiple results.
You have two choices: you can use nested scopes or you can use callable objects.
For example, suppose you wanted to define linear(a,b) which returns a
function f(x) that computes the value a*x+b.  Using nested scopes:
Or using a callable object:
In both cases,
gives a callable object where taxes(10e6) == 0.3 * 10e6 + 2.
The callable object approach has the disadvantage that it is a bit slower and
results in slightly longer code.  However, note that a collection of callables
can share their signature via inheritance:
Object can encapsulate state for several methods:
Here inc(), dec() and reset() act like functions which share the
same counting variable.
In general, try copy.copy() or copy.deepcopy() for the general case.
Not all objects can be copied, but most can.
Some objects can be copied more easily.  Dictionaries have a copy()
method:
Sequences can be copied by slicing:
For an instance x of a user-defined class, dir(x) returns an alphabetized
list of the names containing the instance attributes and methods and attributes
defined by its class.
Generally speaking, it can’t, because objects don’t really have names.
Essentially, assignment always binds a name to a value; the same is true of
def and class statements, but in that case the value is a
callable. Consider the following code:
Arguably the class has a name: even though it is bound to two names and invoked
through the name B the created instance is still reported as an instance of
class A.  However, it is impossible to say whether the instance’s name is a or
b, since both names are bound to the same value.
Generally speaking it should not be necessary for your code to “know the names”
of particular values. Unless you are deliberately writing introspective
programs, this is usually an indication that a change of approach might be
beneficial.
In comp.lang.python, Fredrik Lundh once gave an excellent analogy in answer to
this question:
The same way as you get the name of that cat you found on your porch: the cat
(object) itself cannot tell you its name, and it doesn’t really care – so
the only way to find out what it’s called is to ask all your neighbours
(namespaces) if it’s their cat (object)…
….and don’t be surprised if you’ll find that it’s known by many names, or
no name at all!
Comma is not an operator in Python.  Consider this session:
Since the comma is not an operator, but a separator between expressions the
above is evaluated as if you had entered:
not:
The same is true of the various assignment operators (=, += etc).  They
are not truly operators but syntactic delimiters in assignment statements.
Yes, there is. The syntax is as follows:
Before this syntax was introduced in Python 2.5, a common idiom was to use
logical operators:
However, this idiom is unsafe, as it can give wrong results when on_true
has a false boolean value.  Therefore, it is always better to use
the ... if ... else ... form.
Yes.  Usually this is done by nesting lambda within
lambda.  See the following three examples, slightly adapted from Ulf Bartelt:
Don’t try this at home, kids!
A slash in the argument list of a function denotes that the parameters prior to
it are positional-only.  Positional-only parameters are the ones without an
externally usable name.  Upon calling a function that accepts positional-only
parameters, arguments are mapped to parameters based solely on their position.
For example, divmod() is a function that accepts positional-only
parameters. Its documentation looks like this:
The slash at the end of the parameter list means that both parameters are
positional-only. Thus, calling divmod() with keyword arguments would lead
to an error:"
Why am I getting an UnboundLocalError when the variable has a value?¶,"It can be a surprise to get the UnboundLocalError in previously working
code when it is modified by adding an assignment statement somewhere in
the body of a function.
This code:
works, but this code:
results in an UnboundLocalError:
This is because when you make an assignment to a variable in a scope, that
variable becomes local to that scope and shadows any similarly named variable
in the outer scope.  Since the last statement in foo assigns a new value to
x, the compiler recognizes it as a local variable.  Consequently when the
earlier print(x) attempts to print the uninitialized local variable and
an error results.
In the example above you can access the outer scope variable by declaring it
global:
This explicit declaration is required in order to remind you that (unlike the
superficially analogous situation with class and instance variables) you are
actually modifying the value of the variable in the outer scope:
You can do a similar thing in a nested scope using the nonlocal
keyword:"
What are the rules for local and global variables in Python?¶,"In Python, variables that are only referenced inside a function are implicitly
global.  If a variable is assigned a value anywhere within the function’s body,
it’s assumed to be a local unless explicitly declared as global.
Though a bit surprising at first, a moment’s consideration explains this.  On
one hand, requiring global for assigned variables provides a bar
against unintended side-effects.  On the other hand, if global was required
for all global references, you’d be using global all the time.  You’d have
to declare as global every reference to a built-in function or to a component of
an imported module.  This clutter would defeat the usefulness of the global
declaration for identifying side-effects."
Why do lambdas defined in a loop with different values all return the same result?¶,"Assume you use a for loop to define a few different lambdas (or even plain
functions), e.g.:
This gives you a list that contains 5 lambdas that calculate x**2.  You
might expect that, when called, they would return, respectively, 0, 1,
4, 9, and 16.  However, when you actually try you will see that
they all return 16:
This happens because x is not local to the lambdas, but is defined in
the outer scope, and it is accessed when the lambda is called — not when it
is defined.  At the end of the loop, the value of x is 4, so all the
functions now return 4**2, i.e. 16.  You can also verify this by
changing the value of x and see how the results of the lambdas change:
In order to avoid this, you need to save the values in variables local to the
lambdas, so that they don’t rely on the value of the global x:
Here, n=x creates a new variable n local to the lambda and computed
when the lambda is defined so that it has the same value that x had at
that point in the loop.  This means that the value of n will be 0
in the first lambda, 1 in the second, 2 in the third, and so on.
Therefore each lambda will now return the correct result:
Note that this behaviour is not peculiar to lambdas, but applies to regular
functions too."
How do I share global variables across modules?¶,"The canonical way to share information across modules within a single program is
to create a special module (often called config or cfg).  Just import the config
module in all modules of your application; the module then becomes available as
a global name.  Because there is only one instance of each module, any changes
made to the module object get reflected everywhere.  For example:
config.py:
mod.py:
main.py:
Note that using a module is also the basis for implementing the singleton design
pattern, for the same reason."
What are the “best practices” for using import in a module?¶,"In general, don’t use from modulename import *.  Doing so clutters the
importer’s namespace, and makes it much harder for linters to detect undefined
names.
Import modules at the top of a file.  Doing so makes it clear what other modules
your code requires and avoids questions of whether the module name is in scope.
Using one import per line makes it easy to add and delete module imports, but
using multiple imports per line uses less screen space.
It’s good practice if you import modules in the following order:
standard library modules – e.g. sys, os, argparse, re
third-party library modules (anything installed in Python’s site-packages
directory) – e.g. dateutil, requests, PIL.Image
locally developed modules
It is sometimes necessary to move imports to a function or class to avoid
problems with circular imports.  Gordon McMillan says:
Circular imports are fine where both modules use the “import <module>” form
of import.  They fail when the 2nd module wants to grab a name out of the
first (“from module import name”) and the import is at the top level.  That’s
because names in the 1st are not yet available, because the first module is
busy importing the 2nd.
In this case, if the second module is only used in one function, then the import
can easily be moved into that function.  By the time the import is called, the
first module will have finished initializing, and the second module can do its
import.
It may also be necessary to move imports out of the top level of code if some of
the modules are platform-specific.  In that case, it may not even be possible to
import all of the modules at the top of the file.  In this case, importing the
correct modules in the corresponding platform-specific code is a good option.
Only move imports into a local scope, such as inside a function definition, if
it’s necessary to solve a problem such as avoiding a circular import or are
trying to reduce the initialization time of a module.  This technique is
especially helpful if many of the imports are unnecessary depending on how the
program executes.  You may also want to move imports into a function if the
modules are only ever used in that function.  Note that loading a module the
first time may be expensive because of the one time initialization of the
module, but loading a module multiple times is virtually free, costing only a
couple of dictionary lookups.  Even if the module name has gone out of scope,
the module is probably available in sys.modules."
Why are default values shared between objects?¶,"This type of bug commonly bites neophyte programmers.  Consider this function:
The first time you call this function, mydict contains a single item.  The
second time, mydict contains two items because when foo() begins
executing, mydict starts out with an item already in it.
It is often expected that a function call creates new objects for default
values. This is not what happens. Default values are created exactly once, when
the function is defined.  If that object is changed, like the dictionary in this
example, subsequent calls to the function will refer to this changed object.
By definition, immutable objects such as numbers, strings, tuples, and None,
are safe from change. Changes to mutable objects such as dictionaries, lists,
and class instances can lead to confusion.
Because of this feature, it is good programming practice to not use mutable
objects as default values.  Instead, use None as the default value and
inside the function, check if the parameter is None and create a new
list/dictionary/whatever if it is.  For example, don’t write:
but:
This feature can be useful.  When you have a function that’s time-consuming to
compute, a common technique is to cache the parameters and the resulting value
of each call to the function, and return the cached value if the same value is
requested again.  This is called “memoizing”, and can be implemented like this:
You could use a global variable containing a dictionary instead of the default
value; it’s a matter of taste."
How can I pass optional or keyword parameters from one function to another?¶,"Collect the arguments using the * and ** specifiers in the function’s
parameter list; this gives you the positional arguments as a tuple and the
keyword arguments as a dictionary.  You can then pass these arguments when
calling another function by using * and **:"
What is the difference between arguments and parameters?¶,"Parameters are defined by the names that appear in a
function definition, whereas arguments are the values
actually passed to a function when calling it.  Parameters define what
kind of arguments a function can accept.  For
example, given the function definition:
foo, bar and kwargs are parameters of func.  However, when calling
func, for example:
the values 42, 314, and somevar are arguments."
Why did changing list ‘y’ also change list ‘x’?¶,"If you wrote code like:
you might be wondering why appending an element to y changed x too.
There are two factors that produce this result:
Variables are simply names that refer to objects.  Doing y = x doesn’t
create a copy of the list – it creates a new variable y that refers to
the same object x refers to.  This means that there is only one object
(the list), and both x and y refer to it.
Lists are mutable, which means that you can change their content.
After the call to append(), the content of the mutable object has
changed from [] to [10].  Since both the variables refer to the same
object, using either name accesses the modified value [10].
If we instead assign an immutable object to x:
we can see that in this case x and y are not equal anymore.  This is
because integers are immutable, and when we do x = x + 1 we are not
mutating the int 5 by incrementing its value; instead, we are creating a
new object (the int 6) and assigning it to x (that is, changing which
object x refers to).  After this assignment we have two objects (the ints
6 and 5) and two variables that refer to them (x now refers to
6 but y still refers to 5).
Some operations (for example y.append(10) and y.sort()) mutate the
object, whereas superficially similar operations (for example y = y + [10]
and sorted(y)) create a new object.  In general in Python (and in all cases
in the standard library) a method that mutates an object will return None
to help avoid getting the two types of operations confused.  So if you
mistakenly write y.sort() thinking it will give you a sorted copy of y,
you’ll instead end up with None, which will likely cause your program to
generate an easily diagnosed error.
However, there is one class of operations where the same operation sometimes
has different behaviors with different types:  the augmented assignment
operators.  For example, += mutates lists but not tuples or ints (a_list
+= [1, 2, 3] is equivalent to a_list.extend([1, 2, 3]) and mutates
a_list, whereas some_tuple += (1, 2, 3) and some_int += 1 create
new objects).
In other words:
If we have a mutable object (list, dict, set,
etc.), we can use some specific operations to mutate it and all the variables
that refer to it will see the change.
If we have an immutable object (str, int, tuple,
etc.), all the variables that refer to it will always see the same value,
but operations that transform that value into a new value always return a new
object.
If you want to know if two variables refer to the same object or not, you can
use the is operator, or the built-in function id()."
How do I write a function with output parameters (call by reference)?¶,"Remember that arguments are passed by assignment in Python.  Since assignment
just creates references to objects, there’s no alias between an argument name in
the caller and callee, and so no call-by-reference per se.  You can achieve the
desired effect in a number of ways.
By returning a tuple of the results:
This is almost always the clearest solution.
By using global variables.  This isn’t thread-safe, and is not recommended.
By passing a mutable (changeable in-place) object:
By passing in a dictionary that gets mutated:
Or bundle up values in a class instance:
There’s almost never a good reason to get this complicated.
Your best choice is to return a tuple containing the multiple results."
How do you make a higher order function in Python?¶,"You have two choices: you can use nested scopes or you can use callable objects.
For example, suppose you wanted to define linear(a,b) which returns a
function f(x) that computes the value a*x+b.  Using nested scopes:
Or using a callable object:
In both cases,
gives a callable object where taxes(10e6) == 0.3 * 10e6 + 2.
The callable object approach has the disadvantage that it is a bit slower and
results in slightly longer code.  However, note that a collection of callables
can share their signature via inheritance:
Object can encapsulate state for several methods:
Here inc(), dec() and reset() act like functions which share the
same counting variable."
How do I copy an object in Python?¶,"In general, try copy.copy() or copy.deepcopy() for the general case.
Not all objects can be copied, but most can.
Some objects can be copied more easily.  Dictionaries have a copy()
method:
Sequences can be copied by slicing:"
How can I find the methods or attributes of an object?¶,"For an instance x of a user-defined class, dir(x) returns an alphabetized
list of the names containing the instance attributes and methods and attributes
defined by its class."
How can my code discover the name of an object?¶,"Generally speaking, it can’t, because objects don’t really have names.
Essentially, assignment always binds a name to a value; the same is true of
def and class statements, but in that case the value is a
callable. Consider the following code:
Arguably the class has a name: even though it is bound to two names and invoked
through the name B the created instance is still reported as an instance of
class A.  However, it is impossible to say whether the instance’s name is a or
b, since both names are bound to the same value.
Generally speaking it should not be necessary for your code to “know the names”
of particular values. Unless you are deliberately writing introspective
programs, this is usually an indication that a change of approach might be
beneficial.
In comp.lang.python, Fredrik Lundh once gave an excellent analogy in answer to
this question:
The same way as you get the name of that cat you found on your porch: the cat
(object) itself cannot tell you its name, and it doesn’t really care – so
the only way to find out what it’s called is to ask all your neighbours
(namespaces) if it’s their cat (object)…
….and don’t be surprised if you’ll find that it’s known by many names, or
no name at all!"
What’s up with the comma operator’s precedence?¶,"Comma is not an operator in Python.  Consider this session:
Since the comma is not an operator, but a separator between expressions the
above is evaluated as if you had entered:
not:
The same is true of the various assignment operators (=, += etc).  They
are not truly operators but syntactic delimiters in assignment statements."
Is there an equivalent of C’s “?:” ternary operator?¶,"Yes, there is. The syntax is as follows:
Before this syntax was introduced in Python 2.5, a common idiom was to use
logical operators:
However, this idiom is unsafe, as it can give wrong results when on_true
has a false boolean value.  Therefore, it is always better to use
the ... if ... else ... form."
Is it possible to write obfuscated one-liners in Python?¶,"Yes.  Usually this is done by nesting lambda within
lambda.  See the following three examples, slightly adapted from Ulf Bartelt:
Don’t try this at home, kids!"
What does the slash(/) in the parameter list of a function mean?¶,"A slash in the argument list of a function denotes that the parameters prior to
it are positional-only.  Positional-only parameters are the ones without an
externally usable name.  Upon calling a function that accepts positional-only
parameters, arguments are mapped to parameters based solely on their position.
For example, divmod() is a function that accepts positional-only
parameters. Its documentation looks like this:
The slash at the end of the parameter list means that both parameters are
positional-only. Thus, calling divmod() with keyword arguments would lead
to an error:"
How do I specify hexadecimal and octal integers?¶,"To specify an octal digit, precede the octal value with a zero, and then a lower
or uppercase “o”.  For example, to set the variable “a” to the octal value “10”
(8 in decimal), type:
Hexadecimal is just as easy.  Simply precede the hexadecimal number with a zero,
and then a lower or uppercase “x”.  Hexadecimal digits can be specified in lower
or uppercase.  For example, in the Python interpreter:
It’s primarily driven by the desire that i % j have the same sign as j.
If you want that, and also want:
then integer division has to return the floor.  C also requires that identity to
hold, and then compilers that truncate i // j need to make i % j have
the same sign as i.
There are few real use cases for i % j when j is negative.  When j
is positive, there are many, and in virtually all of them it’s more useful for
i % j to be >= 0.  If the clock says 10 now, what did it say 200 hours
ago?  -190 % 12 == 2 is useful; -190 % 12 == -10 is a bug waiting to
bite.
Trying to lookup an int literal attribute in the normal manner gives
a SyntaxError because the period is seen as a decimal point:
The solution is to separate the literal from the period
with either a space or parentheses.
For integers, use the built-in int() type constructor, e.g. int('144')
== 144.  Similarly, float() converts to floating-point,
e.g. float('144') == 144.0.
By default, these interpret the number as decimal, so that int('0144') ==
144 holds true, and int('0x144') raises ValueError. int(string,
base) takes the base to convert from as a second optional argument, so int(
'0x144', 16) == 324.  If the base is specified as 0, the number is interpreted
using Python’s rules: a leading ‘0o’ indicates octal, and ‘0x’ indicates a hex
number.
Do not use the built-in function eval() if all you need is to convert
strings to numbers.  eval() will be significantly slower and it presents a
security risk: someone could pass you a Python expression that might have
unwanted side effects.  For example, someone could pass
__import__('os').system(""rm -rf $HOME"") which would erase your home
directory.
eval() also has the effect of interpreting numbers as Python expressions,
so that e.g. eval('09') gives a syntax error because Python does not allow
leading ‘0’ in a decimal number (except ‘0’).
To convert, e.g., the number 144 to the string '144', use the built-in type
constructor str().  If you want a hexadecimal or octal representation, use
the built-in functions hex() or oct().  For fancy formatting, see
the f-strings and Format String Syntax sections,
e.g. ""{:04d}"".format(144) yields
'0144' and ""{:.3f}"".format(1.0/3.0) yields '0.333'.
You can’t, because strings are immutable.  In most situations, you should
simply construct a new string from the various parts you want to assemble
it from.  However, if you need an object with the ability to modify in-place
unicode data, try using an io.StringIO object or the array
module:
There are various techniques.
The best is to use a dictionary that maps strings to functions.  The primary
advantage of this technique is that the strings do not need to match the names
of the functions.  This is also the primary technique used to emulate a case
construct:
Use the built-in function getattr():
Note that getattr() works on any object, including classes, class
instances, modules, and so on.
This is used in several places in the standard library, like this:
Use locals() to resolve the function name:
You can use S.rstrip(""\r\n"") to remove all occurrences of any line
terminator from the end of the string S without removing other trailing
whitespace.  If the string S represents more than one line, with several
empty lines at the end, the line terminators for all the blank lines will
be removed:
Since this is typically only desired when reading text one line at a time, using
S.rstrip() this way works well.
Not as such.
For simple input parsing, the easiest approach is usually to split the line into
whitespace-delimited words using the split() method of string objects
and then convert decimal strings to numeric values using int() or
float().  split() supports an optional “sep” parameter which is useful
if the line uses something other than whitespace as a separator.
For more complicated input parsing, regular expressions are more powerful
than C’s sscanf and better suited for the task.
See the Unicode HOWTO.
A raw string ending with an odd number of backslashes will escape the string’s quote:
There are several workarounds for this. One is to use regular strings and double
the backslashes:
Another is to concatenate a regular string containing an escaped backslash to the
raw string:
It is also possible to use os.path.join() to append a backslash on Windows:
Note that while a backslash will “escape” a quote for the purposes of
determining where the raw string ends, no escaping occurs when interpreting the
value of the raw string. That is, the backslash remains present in the value of
the raw string:
Also see the specification in the language reference."
How do I specify hexadecimal and octal integers?¶,"To specify an octal digit, precede the octal value with a zero, and then a lower
or uppercase “o”.  For example, to set the variable “a” to the octal value “10”
(8 in decimal), type:
Hexadecimal is just as easy.  Simply precede the hexadecimal number with a zero,
and then a lower or uppercase “x”.  Hexadecimal digits can be specified in lower
or uppercase.  For example, in the Python interpreter:"
Why does -22 // 10 return -3?¶,"It’s primarily driven by the desire that i % j have the same sign as j.
If you want that, and also want:
then integer division has to return the floor.  C also requires that identity to
hold, and then compilers that truncate i // j need to make i % j have
the same sign as i.
There are few real use cases for i % j when j is negative.  When j
is positive, there are many, and in virtually all of them it’s more useful for
i % j to be >= 0.  If the clock says 10 now, what did it say 200 hours
ago?  -190 % 12 == 2 is useful; -190 % 12 == -10 is a bug waiting to
bite."
How do I get int literal attribute instead of SyntaxError?¶,"Trying to lookup an int literal attribute in the normal manner gives
a SyntaxError because the period is seen as a decimal point:
The solution is to separate the literal from the period
with either a space or parentheses."
How do I convert a string to a number?¶,"For integers, use the built-in int() type constructor, e.g. int('144')
== 144.  Similarly, float() converts to floating-point,
e.g. float('144') == 144.0.
By default, these interpret the number as decimal, so that int('0144') ==
144 holds true, and int('0x144') raises ValueError. int(string,
base) takes the base to convert from as a second optional argument, so int(
'0x144', 16) == 324.  If the base is specified as 0, the number is interpreted
using Python’s rules: a leading ‘0o’ indicates octal, and ‘0x’ indicates a hex
number.
Do not use the built-in function eval() if all you need is to convert
strings to numbers.  eval() will be significantly slower and it presents a
security risk: someone could pass you a Python expression that might have
unwanted side effects.  For example, someone could pass
__import__('os').system(""rm -rf $HOME"") which would erase your home
directory.
eval() also has the effect of interpreting numbers as Python expressions,
so that e.g. eval('09') gives a syntax error because Python does not allow
leading ‘0’ in a decimal number (except ‘0’)."
How do I convert a number to a string?¶,"To convert, e.g., the number 144 to the string '144', use the built-in type
constructor str().  If you want a hexadecimal or octal representation, use
the built-in functions hex() or oct().  For fancy formatting, see
the f-strings and Format String Syntax sections,
e.g. ""{:04d}"".format(144) yields
'0144' and ""{:.3f}"".format(1.0/3.0) yields '0.333'."
How do I modify a string in place?¶,"You can’t, because strings are immutable.  In most situations, you should
simply construct a new string from the various parts you want to assemble
it from.  However, if you need an object with the ability to modify in-place
unicode data, try using an io.StringIO object or the array
module:"
How do I use strings to call functions/methods?¶,"There are various techniques.
The best is to use a dictionary that maps strings to functions.  The primary
advantage of this technique is that the strings do not need to match the names
of the functions.  This is also the primary technique used to emulate a case
construct:
Use the built-in function getattr():
Note that getattr() works on any object, including classes, class
instances, modules, and so on.
This is used in several places in the standard library, like this:
Use locals() to resolve the function name:"
Is there an equivalent to Perl’s chomp() for removing trailing newlines from strings?¶,"You can use S.rstrip(""\r\n"") to remove all occurrences of any line
terminator from the end of the string S without removing other trailing
whitespace.  If the string S represents more than one line, with several
empty lines at the end, the line terminators for all the blank lines will
be removed:
Since this is typically only desired when reading text one line at a time, using
S.rstrip() this way works well."
Is there a scanf() or sscanf() equivalent?¶,"Not as such.
For simple input parsing, the easiest approach is usually to split the line into
whitespace-delimited words using the split() method of string objects
and then convert decimal strings to numeric values using int() or
float().  split() supports an optional “sep” parameter which is useful
if the line uses something other than whitespace as a separator.
For more complicated input parsing, regular expressions are more powerful
than C’s sscanf and better suited for the task."
What does ‘UnicodeDecodeError’ or ‘UnicodeEncodeError’ error  mean?¶,See the Unicode HOWTO.
Can I end a raw string with an odd number of backslashes?¶,"A raw string ending with an odd number of backslashes will escape the string’s quote:
There are several workarounds for this. One is to use regular strings and double
the backslashes:
Another is to concatenate a regular string containing an escaped backslash to the
raw string:
It is also possible to use os.path.join() to append a backslash on Windows:
Note that while a backslash will “escape” a quote for the purposes of
determining where the raw string ends, no escaping occurs when interpreting the
value of the raw string. That is, the backslash remains present in the value of
the raw string:
Also see the specification in the language reference."
My program is too slow. How do I speed it up?¶,"That’s a tough one, in general.  First, here are a list of things to
remember before diving further:
Performance characteristics vary across Python implementations.  This FAQ
focuses on CPython.
Behaviour can vary across operating systems, especially when talking about
I/O or multi-threading.
You should always find the hot spots in your program before attempting to
optimize any code (see the profile module).
Writing benchmark scripts will allow you to iterate quickly when searching
for improvements (see the timeit module).
It is highly recommended to have good code coverage (through unit testing
or any other technique) before potentially introducing regressions hidden
in sophisticated optimizations.
That being said, there are many tricks to speed up Python code.  Here are
some general principles which go a long way towards reaching acceptable
performance levels:
Making your algorithms faster (or changing to faster ones) can yield
much larger benefits than trying to sprinkle micro-optimization tricks
all over your code.
Use the right data structures.  Study documentation for the Built-in Types
and the collections module.
When the standard library provides a primitive for doing something, it is
likely (although not guaranteed) to be faster than any alternative you
may come up with.  This is doubly true for primitives written in C, such
as builtins and some extension types.  For example, be sure to use
either the list.sort() built-in method or the related sorted()
function to do sorting (and see the Sorting Techniques for examples
of moderately advanced usage).
Abstractions tend to create indirections and force the interpreter to work
more.  If the levels of indirection outweigh the amount of useful work
done, your program will be slower.  You should avoid excessive abstraction,
especially under the form of tiny functions or methods (which are also often
detrimental to readability).
If you have reached the limit of what pure Python can allow, there are tools
to take you further away.  For example, Cython can
compile a slightly modified version of Python code into a C extension, and
can be used on many different platforms.  Cython can take advantage of
compilation (and optional type annotations) to make your code significantly
faster than when interpreted.  If you are confident in your C programming
skills, you can also write a C extension module
yourself.
See also
The wiki page devoted to performance tips.
str and bytes objects are immutable, therefore concatenating
many strings together is inefficient as each concatenation creates a new
object.  In the general case, the total runtime cost is quadratic in the
total string length.
To accumulate many str objects, the recommended idiom is to place
them into a list and call str.join() at the end:
(another reasonably efficient idiom is to use io.StringIO)
To accumulate many bytes objects, the recommended idiom is to extend
a bytearray object using in-place concatenation (the += operator):"
My program is too slow. How do I speed it up?¶,"That’s a tough one, in general.  First, here are a list of things to
remember before diving further:
Performance characteristics vary across Python implementations.  This FAQ
focuses on CPython.
Behaviour can vary across operating systems, especially when talking about
I/O or multi-threading.
You should always find the hot spots in your program before attempting to
optimize any code (see the profile module).
Writing benchmark scripts will allow you to iterate quickly when searching
for improvements (see the timeit module).
It is highly recommended to have good code coverage (through unit testing
or any other technique) before potentially introducing regressions hidden
in sophisticated optimizations.
That being said, there are many tricks to speed up Python code.  Here are
some general principles which go a long way towards reaching acceptable
performance levels:
Making your algorithms faster (or changing to faster ones) can yield
much larger benefits than trying to sprinkle micro-optimization tricks
all over your code.
Use the right data structures.  Study documentation for the Built-in Types
and the collections module.
When the standard library provides a primitive for doing something, it is
likely (although not guaranteed) to be faster than any alternative you
may come up with.  This is doubly true for primitives written in C, such
as builtins and some extension types.  For example, be sure to use
either the list.sort() built-in method or the related sorted()
function to do sorting (and see the Sorting Techniques for examples
of moderately advanced usage).
Abstractions tend to create indirections and force the interpreter to work
more.  If the levels of indirection outweigh the amount of useful work
done, your program will be slower.  You should avoid excessive abstraction,
especially under the form of tiny functions or methods (which are also often
detrimental to readability).
If you have reached the limit of what pure Python can allow, there are tools
to take you further away.  For example, Cython can
compile a slightly modified version of Python code into a C extension, and
can be used on many different platforms.  Cython can take advantage of
compilation (and optional type annotations) to make your code significantly
faster than when interpreted.  If you are confident in your C programming
skills, you can also write a C extension module
yourself.
See also
The wiki page devoted to performance tips."
What is the most efficient way to concatenate many strings together?¶,"str and bytes objects are immutable, therefore concatenating
many strings together is inefficient as each concatenation creates a new
object.  In the general case, the total runtime cost is quadratic in the
total string length.
To accumulate many str objects, the recommended idiom is to place
them into a list and call str.join() at the end:
(another reasonably efficient idiom is to use io.StringIO)
To accumulate many bytes objects, the recommended idiom is to extend
a bytearray object using in-place concatenation (the += operator):"
How do I convert between tuples and lists?¶,"The type constructor tuple(seq) converts any sequence (actually, any
iterable) into a tuple with the same items in the same order.
For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple('abc')
yields ('a', 'b', 'c').  If the argument is a tuple, it does not make a copy
but returns the same object, so it is cheap to call tuple() when you
aren’t sure that an object is already a tuple.
The type constructor list(seq) converts any sequence or iterable into a list
with the same items in the same order.  For example, list((1, 2, 3)) yields
[1, 2, 3] and list('abc') yields ['a', 'b', 'c'].  If the argument
is a list, it makes a copy just like seq[:] would.
Python sequences are indexed with positive numbers and negative numbers.  For
positive numbers 0 is the first index 1 is the second index and so forth.  For
negative indices -1 is the last index and -2 is the penultimate (next to last)
index and so forth.  Think of seq[-n] as the same as seq[len(seq)-n].
Using negative indices can be very convenient.  For example S[:-1] is all of
the string except for its last character, which is useful for removing the
trailing newline from a string.
Use the reversed() built-in function:
This won’t touch your original sequence, but build a new copy with reversed
order to iterate over.
See the Python Cookbook for a long discussion of many ways to do this:
https://code.activestate.com/recipes/52560/
If you don’t mind reordering the list, sort it and then scan from the end of the
list, deleting duplicates as you go:
If all elements of the list may be used as set keys (i.e. they are all
hashable) this is often faster
This converts the list into a set, thereby removing duplicates, and then back
into a list.
As with removing duplicates, explicitly iterating in reverse with a
delete condition is one possibility.  However, it is easier and faster
to use slice replacement with an implicit or explicit forward iteration.
Here are three variations.:
The list comprehension may be fastest.
Use a list:
Lists are equivalent to C or Pascal arrays in their time complexity; the primary
difference is that a Python list can contain objects of many different types.
The array module also provides methods for creating arrays of fixed types
with compact representations, but they are slower to index than lists.  Also
note that NumPy
and other third party packages define array-like structures with
various characteristics as well.
To get Lisp-style linked lists, you can emulate cons cells using tuples:
If mutability is desired, you could use lists instead of tuples.  Here the
analogue of a Lisp car is lisp_list[0] and the analogue of cdr is
lisp_list[1].  Only do this if you’re sure you really need to, because it’s
usually a lot slower than using Python lists.
You probably tried to make a multidimensional array like this:
This looks correct if you print it:
But when you assign a value, it shows up in multiple places:
The reason is that replicating a list with * doesn’t create copies, it only
creates references to the existing objects.  The *3 creates a list
containing 3 references to the same list of length two.  Changes to one row will
show in all rows, which is almost certainly not what you want.
The suggested approach is to create a list of the desired length first and then
fill in each element with a newly created list:
This generates a list containing 3 different lists of length two.  You can also
use a list comprehension:
Or, you can use an extension that provides a matrix datatype; NumPy is the best known.
To call a method or function and accumulate the return values is a list,
a list comprehension is an elegant solution:
To just run the method or function without saving the return values,
a plain for loop will suffice:
This is because of a combination of the fact that augmented assignment
operators are assignment operators, and the difference between mutable and
immutable objects in Python.
This discussion applies in general when augmented assignment operators are
applied to elements of a tuple that point to mutable objects, but we’ll use
a list and += as our exemplar.
If you wrote:
The reason for the exception should be immediately clear: 1 is added to the
object a_tuple[0] points to (1), producing the result object, 2,
but when we attempt to assign the result of the computation, 2, to element
0 of the tuple, we get an error because we can’t change what an element of
a tuple points to.
Under the covers, what this augmented assignment statement is doing is
approximately this:
It is the assignment part of the operation that produces the error, since a
tuple is immutable.
When you write something like:
The exception is a bit more surprising, and even more surprising is the fact
that even though there was an error, the append worked:
To see why this happens, you need to know that (a) if an object implements an
__iadd__() magic method, it gets called when the += augmented
assignment
is executed, and its return value is what gets used in the assignment statement;
and (b) for lists, __iadd__() is equivalent to calling extend() on the list
and returning the list.  That’s why we say that for lists, += is a
“shorthand” for list.extend():
This is equivalent to:
The object pointed to by a_list has been mutated, and the pointer to the
mutated object is assigned back to a_list.  The end result of the
assignment is a no-op, since it is a pointer to the same object that a_list
was previously pointing to, but the assignment still happens.
Thus, in our tuple example what is happening is equivalent to:
The __iadd__() succeeds, and thus the list is extended, but even though
result points to the same object that a_tuple[0] already points to,
that final assignment still results in an error, because tuples are immutable.
The technique, attributed to Randal Schwartz of the Perl community, sorts the
elements of a list by a metric which maps each element to its “sort value”. In
Python, use the key argument for the list.sort() method:
Merge them into an iterator of tuples, sort the resulting list, and then pick
out the element you want."
How do I convert between tuples and lists?¶,"The type constructor tuple(seq) converts any sequence (actually, any
iterable) into a tuple with the same items in the same order.
For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple('abc')
yields ('a', 'b', 'c').  If the argument is a tuple, it does not make a copy
but returns the same object, so it is cheap to call tuple() when you
aren’t sure that an object is already a tuple.
The type constructor list(seq) converts any sequence or iterable into a list
with the same items in the same order.  For example, list((1, 2, 3)) yields
[1, 2, 3] and list('abc') yields ['a', 'b', 'c'].  If the argument
is a list, it makes a copy just like seq[:] would."
What’s a negative index?¶,"Python sequences are indexed with positive numbers and negative numbers.  For
positive numbers 0 is the first index 1 is the second index and so forth.  For
negative indices -1 is the last index and -2 is the penultimate (next to last)
index and so forth.  Think of seq[-n] as the same as seq[len(seq)-n].
Using negative indices can be very convenient.  For example S[:-1] is all of
the string except for its last character, which is useful for removing the
trailing newline from a string."
How do I iterate over a sequence in reverse order?¶,"Use the reversed() built-in function:
This won’t touch your original sequence, but build a new copy with reversed
order to iterate over."
How do you remove duplicates from a list?¶,"See the Python Cookbook for a long discussion of many ways to do this:
https://code.activestate.com/recipes/52560/
If you don’t mind reordering the list, sort it and then scan from the end of the
list, deleting duplicates as you go:
If all elements of the list may be used as set keys (i.e. they are all
hashable) this is often faster
This converts the list into a set, thereby removing duplicates, and then back
into a list."
How do you remove multiple items from a list¶,"As with removing duplicates, explicitly iterating in reverse with a
delete condition is one possibility.  However, it is easier and faster
to use slice replacement with an implicit or explicit forward iteration.
Here are three variations.:
The list comprehension may be fastest."
How do you make an array in Python?¶,"Use a list:
Lists are equivalent to C or Pascal arrays in their time complexity; the primary
difference is that a Python list can contain objects of many different types.
The array module also provides methods for creating arrays of fixed types
with compact representations, but they are slower to index than lists.  Also
note that NumPy
and other third party packages define array-like structures with
various characteristics as well.
To get Lisp-style linked lists, you can emulate cons cells using tuples:
If mutability is desired, you could use lists instead of tuples.  Here the
analogue of a Lisp car is lisp_list[0] and the analogue of cdr is
lisp_list[1].  Only do this if you’re sure you really need to, because it’s
usually a lot slower than using Python lists."
How do I create a multidimensional list?¶,"You probably tried to make a multidimensional array like this:
This looks correct if you print it:
But when you assign a value, it shows up in multiple places:
The reason is that replicating a list with * doesn’t create copies, it only
creates references to the existing objects.  The *3 creates a list
containing 3 references to the same list of length two.  Changes to one row will
show in all rows, which is almost certainly not what you want.
The suggested approach is to create a list of the desired length first and then
fill in each element with a newly created list:
This generates a list containing 3 different lists of length two.  You can also
use a list comprehension:
Or, you can use an extension that provides a matrix datatype; NumPy is the best known."
How do I apply a method or function to a sequence of objects?¶,"To call a method or function and accumulate the return values is a list,
a list comprehension is an elegant solution:
To just run the method or function without saving the return values,
a plain for loop will suffice:"
Why does a_tuple[i] += [‘item’] raise an exception when the addition works?¶,"This is because of a combination of the fact that augmented assignment
operators are assignment operators, and the difference between mutable and
immutable objects in Python.
This discussion applies in general when augmented assignment operators are
applied to elements of a tuple that point to mutable objects, but we’ll use
a list and += as our exemplar.
If you wrote:
The reason for the exception should be immediately clear: 1 is added to the
object a_tuple[0] points to (1), producing the result object, 2,
but when we attempt to assign the result of the computation, 2, to element
0 of the tuple, we get an error because we can’t change what an element of
a tuple points to.
Under the covers, what this augmented assignment statement is doing is
approximately this:
It is the assignment part of the operation that produces the error, since a
tuple is immutable.
When you write something like:
The exception is a bit more surprising, and even more surprising is the fact
that even though there was an error, the append worked:
To see why this happens, you need to know that (a) if an object implements an
__iadd__() magic method, it gets called when the += augmented
assignment
is executed, and its return value is what gets used in the assignment statement;
and (b) for lists, __iadd__() is equivalent to calling extend() on the list
and returning the list.  That’s why we say that for lists, += is a
“shorthand” for list.extend():
This is equivalent to:
The object pointed to by a_list has been mutated, and the pointer to the
mutated object is assigned back to a_list.  The end result of the
assignment is a no-op, since it is a pointer to the same object that a_list
was previously pointing to, but the assignment still happens.
Thus, in our tuple example what is happening is equivalent to:
The __iadd__() succeeds, and thus the list is extended, but even though
result points to the same object that a_tuple[0] already points to,
that final assignment still results in an error, because tuples are immutable."
I want to do a complicated sort: can you do a Schwartzian Transform in Python?¶,"The technique, attributed to Randal Schwartz of the Perl community, sorts the
elements of a list by a metric which maps each element to its “sort value”. In
Python, use the key argument for the list.sort() method:"
How can I sort one list by values from another list?¶,"Merge them into an iterator of tuples, sort the resulting list, and then pick
out the element you want."
What is a class?¶,"A class is the particular object type created by executing a class statement.
Class objects are used as templates to create instance objects, which embody
both the data (attributes) and code (methods) specific to a datatype.
A class can be based on one or more other classes, called its base class(es). It
then inherits the attributes and methods of its base classes. This allows an
object model to be successively refined by inheritance.  You might have a
generic Mailbox class that provides basic accessor methods for a mailbox,
and subclasses such as MboxMailbox, MaildirMailbox, OutlookMailbox
that handle various specific mailbox formats.
A method is a function on some object x that you normally call as
x.name(arguments...).  Methods are defined as functions inside the class
definition:
Self is merely a conventional name for the first argument of a method.  A method
defined as meth(self, a, b, c) should be called as x.meth(a, b, c) for
some instance x of the class in which the definition occurs; the called
method will think it is called as meth(x, a, b, c).
See also Why must ‘self’ be used explicitly in method definitions and calls?.
Use the built-in function isinstance(obj, cls).  You can
check if an object
is an instance of any of a number of classes by providing a tuple instead of a
single class, e.g. isinstance(obj, (class1, class2, ...)), and can also
check whether an object is one of Python’s built-in types, e.g.
isinstance(obj, str) or isinstance(obj, (int, float, complex)).
Note that isinstance() also checks for virtual inheritance from an
abstract base class.  So, the test will return True for a
registered class even if hasn’t directly or indirectly inherited from it.  To
test for “true inheritance”, scan the MRO of the class:
Note that most programs do not use isinstance() on user-defined classes
very often.  If you are developing the classes yourself, a more proper
object-oriented style is to define methods on the classes that encapsulate a
particular behaviour, instead of checking the object’s class and doing a
different thing based on what class it is.  For example, if you have a function
that does something:
A better approach is to define a search() method on all the classes and just
call it:
Delegation is an object oriented technique (also called a design pattern).
Let’s say you have an object x and want to change the behaviour of just one
of its methods.  You can create a new class that provides a new implementation
of the method you’re interested in changing and delegates all other methods to
the corresponding method of x.
Python programmers can easily implement delegation.  For example, the following
class implements a class that behaves like a file but converts all written data
to uppercase:
Here the UpperOut class redefines the write() method to convert the
argument string to uppercase before calling the underlying
self._outfile.write() method.  All other methods are delegated to the
underlying self._outfile object.  The delegation is accomplished via the
__getattr__() method; consult the language reference
for more information about controlling attribute access.
Note that for more general cases delegation can get trickier. When attributes
must be set as well as retrieved, the class must define a __setattr__()
method too, and it must do so carefully.  The basic implementation of
__setattr__() is roughly equivalent to the following:
Most __setattr__() implementations must modify
self.__dict__ to store
local state for self without causing an infinite recursion.
Use the built-in super() function:
In the example, super() will automatically determine the instance from
which it was called (the self value), look up the method resolution
order (MRO) with type(self).__mro__, and return the next in line after
Derived in the MRO: Base.
You could assign the base class to an alias and derive from the alias.  Then all
you have to change is the value assigned to the alias.  Incidentally, this trick
is also handy if you want to decide dynamically (e.g. depending on availability
of resources) which base class to use.  Example:
Both static data and static methods (in the sense of C++ or Java) are supported
in Python.
For static data, simply define a class attribute.  To assign a new value to the
attribute, you have to explicitly use the class name in the assignment:
c.count also refers to C.count for any c such that isinstance(c,
C) holds, unless overridden by c itself or by some class on the base-class
search path from c.__class__ back to C.
Caution: within a method of C, an assignment like self.count = 42 creates a
new and unrelated instance named “count” in self’s own dict.  Rebinding of a
class-static data name must always specify the class whether inside a method or
not:
Static methods are possible:
However, a far more straightforward way to get the effect of a static method is
via a simple module-level function:
If your code is structured so as to define one class (or tightly related class
hierarchy) per module, this supplies the desired encapsulation.
This answer actually applies to all methods, but the question usually comes up
first in the context of constructors.
In C++ you’d write
In Python you have to write a single constructor that catches all cases using
default arguments.  For example:
This is not entirely equivalent, but close enough in practice.
You could also try a variable-length argument list, e.g.
The same approach works for all method definitions.
Variable names with double leading underscores are “mangled” to provide a simple
but effective way to define class private variables.  Any identifier of the form
__spam (at least two leading underscores, at most one trailing underscore)
is textually replaced with _classname__spam, where classname is the
current class name with any leading underscores stripped.
This doesn’t guarantee privacy: an outside user can still deliberately access
the “_classname__spam” attribute, and private values are visible in the object’s
__dict__.  Many Python programmers never bother to use private variable
names at all.
There are several possible reasons for this.
The del statement does not necessarily call __del__() – it simply
decrements the object’s reference count, and if this reaches zero
__del__() is called.
If your data structures contain circular links (e.g. a tree where each child has
a parent reference and each parent has a list of children) the reference counts
will never go back to zero.  Once in a while Python runs an algorithm to detect
such cycles, but the garbage collector might run some time after the last
reference to your data structure vanishes, so your __del__() method may be
called at an inconvenient and random time. This is inconvenient if you’re trying
to reproduce a problem. Worse, the order in which object’s __del__()
methods are executed is arbitrary.  You can run gc.collect() to force a
collection, but there are pathological cases where objects will never be
collected.
Despite the cycle collector, it’s still a good idea to define an explicit
close() method on objects to be called whenever you’re done with them.  The
close() method can then remove attributes that refer to subobjects.  Don’t
call __del__() directly – __del__() should call close() and
close() should make sure that it can be called more than once for the same
object.
Another way to avoid cyclical references is to use the weakref module,
which allows you to point to objects without incrementing their reference count.
Tree data structures, for instance, should use weak references for their parent
and sibling references (if they need them!).
Finally, if your __del__() method raises an exception, a warning message
is printed to sys.stderr.
Python does not keep track of all instances of a class (or of a built-in type).
You can program the class’s constructor to keep track of all instances by
keeping a list of weak references to each instance.
The id() builtin returns an integer that is guaranteed to be unique during
the lifetime of the object.  Since in CPython, this is the object’s memory
address, it happens frequently that after an object is deleted from memory, the
next freshly created object is allocated at the same position in memory.  This
is illustrated by this example:
The two ids belong to different integer objects that are created before, and
deleted immediately after execution of the id() call.  To be sure that
objects whose id you want to examine are still alive, create another reference
to the object:
The is operator tests for object identity.  The test a is b is
equivalent to id(a) == id(b).
The most important property of an identity test is that an object is always
identical to itself, a is a always returns True.  Identity tests are
usually faster than equality tests.  And unlike equality tests, identity tests
are guaranteed to return a boolean True or False.
However, identity tests can only be substituted for equality tests when
object identity is assured.  Generally, there are three circumstances where
identity is guaranteed:
1) Assignments create new names but do not change object identity.  After the
assignment new = old, it is guaranteed that new is old.
2) Putting an object in a container that stores object references does not
change object identity.  After the list assignment s[0] = x, it is
guaranteed that s[0] is x.
3) If an object is a singleton, it means that only one instance of that object
can exist.  After the assignments a = None and b = None, it is
guaranteed that a is b because None is a singleton.
In most other circumstances, identity tests are inadvisable and equality tests
are preferred.  In particular, identity tests should not be used to check
constants such as int and str which aren’t guaranteed to be
singletons:
Likewise, new instances of mutable containers are never identical:
In the standard library code, you will see several common patterns for
correctly using identity tests:
1) As recommended by PEP 8, an identity test is the preferred way to check
for None.  This reads like plain English in code and avoids confusion with
other objects that may have boolean values that evaluate to false.
2) Detecting optional arguments can be tricky when None is a valid input
value.  In those situations, you can create a singleton sentinel object
guaranteed to be distinct from other objects.  For example, here is how
to implement a method that behaves like dict.pop():
3) Container implementations sometimes need to augment equality tests with
identity tests.  This prevents the code from being confused by objects such as
float('NaN') that are not equal to themselves.
For example, here is the implementation of
collections.abc.Sequence.__contains__():
When subclassing an immutable type, override the __new__() method
instead of the __init__() method.  The latter only runs after an
instance is created, which is too late to alter data in an immutable
instance.
All of these immutable classes have a different signature than their
parent class:
The classes can be used like this:
The two principal tools for caching methods are
functools.cached_property() and functools.lru_cache().  The
former stores results at the instance level and the latter at the class
level.
The cached_property approach only works with methods that do not take
any arguments.  It does not create a reference to the instance.  The
cached method result will be kept only as long as the instance is alive.
The advantage is that when an instance is no longer used, the cached
method result will be released right away.  The disadvantage is that if
instances accumulate, so too will the accumulated method results.  They
can grow without bound.
The lru_cache approach works with methods that have hashable
arguments.  It creates a reference to the instance unless special
efforts are made to pass in weak references.
The advantage of the least recently used algorithm is that the cache is
bounded by the specified maxsize.  The disadvantage is that instances
are kept alive until they age out of the cache or until the cache is
cleared.
This example shows the various techniques:
The above example assumes that the station_id never changes.  If the
relevant instance attributes are mutable, the cached_property approach
can’t be made to work because it cannot detect changes to the
attributes.
To make the lru_cache approach work when the station_id is mutable,
the class needs to define the __eq__() and __hash__()
methods so that the cache can detect relevant attribute updates:"
What is a class?¶,"A class is the particular object type created by executing a class statement.
Class objects are used as templates to create instance objects, which embody
both the data (attributes) and code (methods) specific to a datatype.
A class can be based on one or more other classes, called its base class(es). It
then inherits the attributes and methods of its base classes. This allows an
object model to be successively refined by inheritance.  You might have a
generic Mailbox class that provides basic accessor methods for a mailbox,
and subclasses such as MboxMailbox, MaildirMailbox, OutlookMailbox
that handle various specific mailbox formats."
What is a method?¶,"A method is a function on some object x that you normally call as
x.name(arguments...).  Methods are defined as functions inside the class
definition:"
What is self?¶,"Self is merely a conventional name for the first argument of a method.  A method
defined as meth(self, a, b, c) should be called as x.meth(a, b, c) for
some instance x of the class in which the definition occurs; the called
method will think it is called as meth(x, a, b, c).
See also Why must ‘self’ be used explicitly in method definitions and calls?."
How do I check if an object is an instance of a given class or of a subclass of it?¶,"Use the built-in function isinstance(obj, cls).  You can
check if an object
is an instance of any of a number of classes by providing a tuple instead of a
single class, e.g. isinstance(obj, (class1, class2, ...)), and can also
check whether an object is one of Python’s built-in types, e.g.
isinstance(obj, str) or isinstance(obj, (int, float, complex)).
Note that isinstance() also checks for virtual inheritance from an
abstract base class.  So, the test will return True for a
registered class even if hasn’t directly or indirectly inherited from it.  To
test for “true inheritance”, scan the MRO of the class:
Note that most programs do not use isinstance() on user-defined classes
very often.  If you are developing the classes yourself, a more proper
object-oriented style is to define methods on the classes that encapsulate a
particular behaviour, instead of checking the object’s class and doing a
different thing based on what class it is.  For example, if you have a function
that does something:
A better approach is to define a search() method on all the classes and just
call it:"
What is delegation?¶,"Delegation is an object oriented technique (also called a design pattern).
Let’s say you have an object x and want to change the behaviour of just one
of its methods.  You can create a new class that provides a new implementation
of the method you’re interested in changing and delegates all other methods to
the corresponding method of x.
Python programmers can easily implement delegation.  For example, the following
class implements a class that behaves like a file but converts all written data
to uppercase:
Here the UpperOut class redefines the write() method to convert the
argument string to uppercase before calling the underlying
self._outfile.write() method.  All other methods are delegated to the
underlying self._outfile object.  The delegation is accomplished via the
__getattr__() method; consult the language reference
for more information about controlling attribute access.
Note that for more general cases delegation can get trickier. When attributes
must be set as well as retrieved, the class must define a __setattr__()
method too, and it must do so carefully.  The basic implementation of
__setattr__() is roughly equivalent to the following:
Most __setattr__() implementations must modify
self.__dict__ to store
local state for self without causing an infinite recursion."
How do I call a method defined in a base class from a derived class that extends it?¶,"Use the built-in super() function:
In the example, super() will automatically determine the instance from
which it was called (the self value), look up the method resolution
order (MRO) with type(self).__mro__, and return the next in line after
Derived in the MRO: Base."
How can I organize my code to make it easier to change the base class?¶,"You could assign the base class to an alias and derive from the alias.  Then all
you have to change is the value assigned to the alias.  Incidentally, this trick
is also handy if you want to decide dynamically (e.g. depending on availability
of resources) which base class to use.  Example:"
How do I create static class data and static class methods?¶,"Both static data and static methods (in the sense of C++ or Java) are supported
in Python.
For static data, simply define a class attribute.  To assign a new value to the
attribute, you have to explicitly use the class name in the assignment:
c.count also refers to C.count for any c such that isinstance(c,
C) holds, unless overridden by c itself or by some class on the base-class
search path from c.__class__ back to C.
Caution: within a method of C, an assignment like self.count = 42 creates a
new and unrelated instance named “count” in self’s own dict.  Rebinding of a
class-static data name must always specify the class whether inside a method or
not:
Static methods are possible:
However, a far more straightforward way to get the effect of a static method is
via a simple module-level function:
If your code is structured so as to define one class (or tightly related class
hierarchy) per module, this supplies the desired encapsulation."
How can I overload constructors (or methods) in Python?¶,"This answer actually applies to all methods, but the question usually comes up
first in the context of constructors.
In C++ you’d write
In Python you have to write a single constructor that catches all cases using
default arguments.  For example:
This is not entirely equivalent, but close enough in practice.
You could also try a variable-length argument list, e.g.
The same approach works for all method definitions."
I try to use __spam and I get an error about _SomeClassName__spam.¶,"Variable names with double leading underscores are “mangled” to provide a simple
but effective way to define class private variables.  Any identifier of the form
__spam (at least two leading underscores, at most one trailing underscore)
is textually replaced with _classname__spam, where classname is the
current class name with any leading underscores stripped.
This doesn’t guarantee privacy: an outside user can still deliberately access
the “_classname__spam” attribute, and private values are visible in the object’s
__dict__.  Many Python programmers never bother to use private variable
names at all."
My class defines __del__ but it is not called when I delete the object.¶,"There are several possible reasons for this.
The del statement does not necessarily call __del__() – it simply
decrements the object’s reference count, and if this reaches zero
__del__() is called.
If your data structures contain circular links (e.g. a tree where each child has
a parent reference and each parent has a list of children) the reference counts
will never go back to zero.  Once in a while Python runs an algorithm to detect
such cycles, but the garbage collector might run some time after the last
reference to your data structure vanishes, so your __del__() method may be
called at an inconvenient and random time. This is inconvenient if you’re trying
to reproduce a problem. Worse, the order in which object’s __del__()
methods are executed is arbitrary.  You can run gc.collect() to force a
collection, but there are pathological cases where objects will never be
collected.
Despite the cycle collector, it’s still a good idea to define an explicit
close() method on objects to be called whenever you’re done with them.  The
close() method can then remove attributes that refer to subobjects.  Don’t
call __del__() directly – __del__() should call close() and
close() should make sure that it can be called more than once for the same
object.
Another way to avoid cyclical references is to use the weakref module,
which allows you to point to objects without incrementing their reference count.
Tree data structures, for instance, should use weak references for their parent
and sibling references (if they need them!).
Finally, if your __del__() method raises an exception, a warning message
is printed to sys.stderr."
How do I get a list of all instances of a given class?¶,"Python does not keep track of all instances of a class (or of a built-in type).
You can program the class’s constructor to keep track of all instances by
keeping a list of weak references to each instance."
Why does the result of id() appear to be not unique?¶,"The id() builtin returns an integer that is guaranteed to be unique during
the lifetime of the object.  Since in CPython, this is the object’s memory
address, it happens frequently that after an object is deleted from memory, the
next freshly created object is allocated at the same position in memory.  This
is illustrated by this example:
The two ids belong to different integer objects that are created before, and
deleted immediately after execution of the id() call.  To be sure that
objects whose id you want to examine are still alive, create another reference
to the object:"
When can I rely on identity tests with the is operator?¶,"The is operator tests for object identity.  The test a is b is
equivalent to id(a) == id(b).
The most important property of an identity test is that an object is always
identical to itself, a is a always returns True.  Identity tests are
usually faster than equality tests.  And unlike equality tests, identity tests
are guaranteed to return a boolean True or False.
However, identity tests can only be substituted for equality tests when
object identity is assured.  Generally, there are three circumstances where
identity is guaranteed:
1) Assignments create new names but do not change object identity.  After the
assignment new = old, it is guaranteed that new is old.
2) Putting an object in a container that stores object references does not
change object identity.  After the list assignment s[0] = x, it is
guaranteed that s[0] is x.
3) If an object is a singleton, it means that only one instance of that object
can exist.  After the assignments a = None and b = None, it is
guaranteed that a is b because None is a singleton.
In most other circumstances, identity tests are inadvisable and equality tests
are preferred.  In particular, identity tests should not be used to check
constants such as int and str which aren’t guaranteed to be
singletons:
Likewise, new instances of mutable containers are never identical:
In the standard library code, you will see several common patterns for
correctly using identity tests:
1) As recommended by PEP 8, an identity test is the preferred way to check
for None.  This reads like plain English in code and avoids confusion with
other objects that may have boolean values that evaluate to false.
2) Detecting optional arguments can be tricky when None is a valid input
value.  In those situations, you can create a singleton sentinel object
guaranteed to be distinct from other objects.  For example, here is how
to implement a method that behaves like dict.pop():
3) Container implementations sometimes need to augment equality tests with
identity tests.  This prevents the code from being confused by objects such as
float('NaN') that are not equal to themselves.
For example, here is the implementation of
collections.abc.Sequence.__contains__():"
How can a subclass control what data is stored in an immutable instance?¶,"When subclassing an immutable type, override the __new__() method
instead of the __init__() method.  The latter only runs after an
instance is created, which is too late to alter data in an immutable
instance.
All of these immutable classes have a different signature than their
parent class:
The classes can be used like this:"
How do I cache method calls?¶,"The two principal tools for caching methods are
functools.cached_property() and functools.lru_cache().  The
former stores results at the instance level and the latter at the class
level.
The cached_property approach only works with methods that do not take
any arguments.  It does not create a reference to the instance.  The
cached method result will be kept only as long as the instance is alive.
The advantage is that when an instance is no longer used, the cached
method result will be released right away.  The disadvantage is that if
instances accumulate, so too will the accumulated method results.  They
can grow without bound.
The lru_cache approach works with methods that have hashable
arguments.  It creates a reference to the instance unless special
efforts are made to pass in weak references.
The advantage of the least recently used algorithm is that the cache is
bounded by the specified maxsize.  The disadvantage is that instances
are kept alive until they age out of the cache or until the cache is
cleared.
This example shows the various techniques:
The above example assumes that the station_id never changes.  If the
relevant instance attributes are mutable, the cached_property approach
can’t be made to work because it cannot detect changes to the
attributes.
To make the lru_cache approach work when the station_id is mutable,
the class needs to define the __eq__() and __hash__()
methods so that the cache can detect relevant attribute updates:"
How do I create a .pyc file?¶,"When a module is imported for the first time (or when the source file has
changed since the current compiled file was created) a .pyc file containing
the compiled code should be created in a __pycache__ subdirectory of the
directory containing the .py file.  The .pyc file will have a
filename that starts with the same name as the .py file, and ends with
.pyc, with a middle component that depends on the particular python
binary that created it.  (See PEP 3147 for details.)
One reason that a .pyc file may not be created is a permissions problem
with the directory containing the source file, meaning that the __pycache__
subdirectory cannot be created. This can happen, for example, if you develop as
one user but run as another, such as if you are testing with a web server.
Unless the PYTHONDONTWRITEBYTECODE environment variable is set,
creation of a .pyc file is automatic if you’re importing a module and Python
has the ability (permissions, free space, etc…) to create a __pycache__
subdirectory and write the compiled module to that subdirectory.
Running Python on a top level script is not considered an import and no
.pyc will be created.  For example, if you have a top-level module
foo.py that imports another module xyz.py, when you run foo (by
typing python foo.py as a shell command), a .pyc will be created for
xyz because xyz is imported, but no .pyc file will be created for
foo since foo.py isn’t being imported.
If you need to create a .pyc file for foo – that is, to create a
.pyc file for a module that is not imported – you can, using the
py_compile and compileall modules.
The py_compile module can manually compile any module.  One way is to use
the compile() function in that module interactively:
This will write the .pyc to a __pycache__ subdirectory in the same
location as foo.py (or you can override that with the optional parameter
cfile).
You can also automatically compile all files in a directory or directories using
the compileall module.  You can do it from the shell prompt by running
compileall.py and providing the path of a directory containing Python files
to compile:
A module can find out its own module name by looking at the predefined global
variable __name__.  If this has the value '__main__', the program is
running as a script.  Many modules that are usually used by importing them also
provide a command-line interface or a self-test, and only execute this code
after checking __name__:
Suppose you have the following modules:
foo.py:
bar.py:
The problem is that the interpreter will perform the following steps:
main imports foo
Empty globals for foo are created
foo is compiled and starts executing
foo imports bar
Empty globals for bar are created
bar is compiled and starts executing
bar imports foo (which is a no-op since there already is a module named foo)
The import mechanism tries to read foo_var from foo globals, to set bar.foo_var = foo.foo_var
The last step fails, because Python isn’t done with interpreting foo yet and
the global symbol dictionary for foo is still empty.
The same thing happens when you use import foo, and then try to access
foo.foo_var in global code.
There are (at least) three possible workarounds for this problem.
Guido van Rossum recommends avoiding all uses of from <module> import ...,
and placing all code inside functions.  Initializations of global variables and
class variables should use constants or built-in functions only.  This means
everything from an imported module is referenced as <module>.<name>.
Jim Roskind suggests performing steps in the following order in each module:
exports (globals, functions, and classes that don’t need imported base
classes)
import statements
active code (including globals that are initialized from imported values).
Van Rossum doesn’t like this approach much because the imports appear in a
strange place, but it does work.
Matthias Urlichs recommends restructuring your code so that the recursive import
is not necessary in the first place.
These solutions are not mutually exclusive.
Consider using the convenience function import_module() from
importlib instead:
For reasons of efficiency as well as consistency, Python only reads the module
file on the first time a module is imported.  If it didn’t, in a program
consisting of many modules where each one imports the same basic module, the
basic module would be parsed and re-parsed many times.  To force re-reading of a
changed module, do this:
Warning: this technique is not 100% fool-proof.  In particular, modules
containing statements like
will continue to work with the old version of the imported objects.  If the
module contains class definitions, existing class instances will not be
updated to use the new class definition.  This can result in the following
paradoxical behaviour:
The nature of the problem is made clear if you print out the “identity” of the
class objects:"
How do I create a .pyc file?¶,"When a module is imported for the first time (or when the source file has
changed since the current compiled file was created) a .pyc file containing
the compiled code should be created in a __pycache__ subdirectory of the
directory containing the .py file.  The .pyc file will have a
filename that starts with the same name as the .py file, and ends with
.pyc, with a middle component that depends on the particular python
binary that created it.  (See PEP 3147 for details.)
One reason that a .pyc file may not be created is a permissions problem
with the directory containing the source file, meaning that the __pycache__
subdirectory cannot be created. This can happen, for example, if you develop as
one user but run as another, such as if you are testing with a web server.
Unless the PYTHONDONTWRITEBYTECODE environment variable is set,
creation of a .pyc file is automatic if you’re importing a module and Python
has the ability (permissions, free space, etc…) to create a __pycache__
subdirectory and write the compiled module to that subdirectory.
Running Python on a top level script is not considered an import and no
.pyc will be created.  For example, if you have a top-level module
foo.py that imports another module xyz.py, when you run foo (by
typing python foo.py as a shell command), a .pyc will be created for
xyz because xyz is imported, but no .pyc file will be created for
foo since foo.py isn’t being imported.
If you need to create a .pyc file for foo – that is, to create a
.pyc file for a module that is not imported – you can, using the
py_compile and compileall modules.
The py_compile module can manually compile any module.  One way is to use
the compile() function in that module interactively:
This will write the .pyc to a __pycache__ subdirectory in the same
location as foo.py (or you can override that with the optional parameter
cfile).
You can also automatically compile all files in a directory or directories using
the compileall module.  You can do it from the shell prompt by running
compileall.py and providing the path of a directory containing Python files
to compile:"
How do I find the current module name?¶,"A module can find out its own module name by looking at the predefined global
variable __name__.  If this has the value '__main__', the program is
running as a script.  Many modules that are usually used by importing them also
provide a command-line interface or a self-test, and only execute this code
after checking __name__:"
How can I have modules that mutually import each other?¶,"Suppose you have the following modules:
foo.py:
bar.py:
The problem is that the interpreter will perform the following steps:
main imports foo
Empty globals for foo are created
foo is compiled and starts executing
foo imports bar
Empty globals for bar are created
bar is compiled and starts executing
bar imports foo (which is a no-op since there already is a module named foo)
The import mechanism tries to read foo_var from foo globals, to set bar.foo_var = foo.foo_var
The last step fails, because Python isn’t done with interpreting foo yet and
the global symbol dictionary for foo is still empty.
The same thing happens when you use import foo, and then try to access
foo.foo_var in global code.
There are (at least) three possible workarounds for this problem.
Guido van Rossum recommends avoiding all uses of from <module> import ...,
and placing all code inside functions.  Initializations of global variables and
class variables should use constants or built-in functions only.  This means
everything from an imported module is referenced as <module>.<name>.
Jim Roskind suggests performing steps in the following order in each module:
exports (globals, functions, and classes that don’t need imported base
classes)
import statements
active code (including globals that are initialized from imported values).
Van Rossum doesn’t like this approach much because the imports appear in a
strange place, but it does work.
Matthias Urlichs recommends restructuring your code so that the recursive import
is not necessary in the first place.
These solutions are not mutually exclusive."
__import__(‘x.y.z’) returns <module ‘x’>; how do I get z?¶,"Consider using the convenience function import_module() from
importlib instead:"
"When I edit an imported module and reimport it, the changes don’t show up.  Why does this happen?¶","For reasons of efficiency as well as consistency, Python only reads the module
file on the first time a module is imported.  If it didn’t, in a program
consisting of many modules where each one imports the same basic module, the
basic module would be parsed and re-parsed many times.  To force re-reading of a
changed module, do this:
Warning: this technique is not 100% fool-proof.  In particular, modules
containing statements like
will continue to work with the old version of the imported objects.  If the
module contains class definitions, existing class instances will not be
updated to use the new class definition.  This can result in the following
paradoxical behaviour:
The nature of the problem is made clear if you print out the “identity” of the
class objects:"
How do I find a module or application to perform task X?¶,"Check the Library Reference to see if there’s a relevant
standard library module.  (Eventually you’ll learn what’s in the standard
library and will be able to skip this step.)
For third-party packages, search the Python Package Index or try Google or
another web search engine.  Searching for “Python” plus a keyword or two for
your topic of interest will usually find something helpful.
If you can’t find a source file for a module it may be a built-in or
dynamically loaded module implemented in C, C++ or other compiled language.
In this case you may not have the source file or it may be something like
mathmodule.c, somewhere in a C source directory (not on the Python Path).
There are (at least) three kinds of modules in Python:
modules written in Python (.py);
modules written in C and dynamically loaded (.dll, .pyd, .so, .sl, etc);
modules written in C and linked with the interpreter; to get a list of these,
type:
You need to do two things: the script file’s mode must be executable and the
first line must begin with #! followed by the path of the Python
interpreter.
The first is done by executing chmod +x scriptfile or perhaps chmod 755
scriptfile.
The second can be done in a number of ways.  The most straightforward way is to
write
as the very first line of your file, using the pathname for where the Python
interpreter is installed on your platform.
If you would like the script to be independent of where the Python interpreter
lives, you can use the env program.  Almost all Unix variants support
the following, assuming the Python interpreter is in a directory on the user’s
PATH:
Don’t do this for CGI scripts.  The PATH variable for CGI scripts is
often very minimal, so you need to use the actual absolute pathname of the
interpreter.
Occasionally, a user’s environment is so full that the /usr/bin/env
program fails; or there’s no env program at all.  In that case, you can try the
following hack (due to Alex Rezinsky):
The minor disadvantage is that this defines the script’s __doc__ string.
However, you can fix that by adding
For Unix variants: The standard Python source distribution comes with a curses
module in the Modules subdirectory, though it’s not compiled by default.
(Note that this is not available in the Windows distribution – there is no
curses module for Windows.)
The curses module supports basic curses features as well as many additional
functions from ncurses and SYSV curses such as colour, alternative character set
support, pads, and mouse support. This means the module isn’t compatible with
operating systems that only have BSD curses, but there don’t seem to be any
currently maintained OSes that fall into this category.
The atexit module provides a register function that is similar to C’s
onexit().
The most common problem is that the signal handler is declared with the wrong
argument list.  It is called as
so it should be declared with two parameters:"
How do I find a module or application to perform task X?¶,"Check the Library Reference to see if there’s a relevant
standard library module.  (Eventually you’ll learn what’s in the standard
library and will be able to skip this step.)
For third-party packages, search the Python Package Index or try Google or
another web search engine.  Searching for “Python” plus a keyword or two for
your topic of interest will usually find something helpful."
"Where is the math.py (socket.py, regex.py, etc.) source file?¶","If you can’t find a source file for a module it may be a built-in or
dynamically loaded module implemented in C, C++ or other compiled language.
In this case you may not have the source file or it may be something like
mathmodule.c, somewhere in a C source directory (not on the Python Path).
There are (at least) three kinds of modules in Python:
modules written in Python (.py);
modules written in C and dynamically loaded (.dll, .pyd, .so, .sl, etc);
modules written in C and linked with the interpreter; to get a list of these,
type:"
How do I make a Python script executable on Unix?¶,"You need to do two things: the script file’s mode must be executable and the
first line must begin with #! followed by the path of the Python
interpreter.
The first is done by executing chmod +x scriptfile or perhaps chmod 755
scriptfile.
The second can be done in a number of ways.  The most straightforward way is to
write
as the very first line of your file, using the pathname for where the Python
interpreter is installed on your platform.
If you would like the script to be independent of where the Python interpreter
lives, you can use the env program.  Almost all Unix variants support
the following, assuming the Python interpreter is in a directory on the user’s
PATH:
Don’t do this for CGI scripts.  The PATH variable for CGI scripts is
often very minimal, so you need to use the actual absolute pathname of the
interpreter.
Occasionally, a user’s environment is so full that the /usr/bin/env
program fails; or there’s no env program at all.  In that case, you can try the
following hack (due to Alex Rezinsky):
The minor disadvantage is that this defines the script’s __doc__ string.
However, you can fix that by adding"
Is there a curses/termcap package for Python?¶,"For Unix variants: The standard Python source distribution comes with a curses
module in the Modules subdirectory, though it’s not compiled by default.
(Note that this is not available in the Windows distribution – there is no
curses module for Windows.)
The curses module supports basic curses features as well as many additional
functions from ncurses and SYSV curses such as colour, alternative character set
support, pads, and mouse support. This means the module isn’t compatible with
operating systems that only have BSD curses, but there don’t seem to be any
currently maintained OSes that fall into this category."
Is there an equivalent to C’s onexit() in Python?¶,"The atexit module provides a register function that is similar to C’s
onexit()."
Why don’t my signal handlers work?¶,"The most common problem is that the signal handler is declared with the wrong
argument list.  It is called as
so it should be declared with two parameters:"
How do I test a Python program or component?¶,"Python comes with two testing frameworks.  The doctest module finds
examples in the docstrings for a module and runs them, comparing the output with
the expected output given in the docstring.
The unittest module is a fancier testing framework modelled on Java and
Smalltalk testing frameworks.
To make testing easier, you should use good modular design in your program.
Your program should have almost all functionality
encapsulated in either functions or class methods – and this sometimes has the
surprising and delightful effect of making the program run faster (because local
variable accesses are faster than global accesses).  Furthermore the program
should avoid depending on mutating global variables, since this makes testing
much more difficult to do.
The “global main logic” of your program may be as simple as
at the bottom of the main module of your program.
Once your program is organized as a tractable collection of function and class
behaviours, you should write test functions that exercise the behaviours.  A
test suite that automates a sequence of tests can be associated with each module.
This sounds like a lot of work, but since Python is so terse and flexible it’s
surprisingly easy.  You can make coding much more pleasant and fun by writing
your test functions in parallel with the “production code”, since this makes it
easy to find bugs and even design flaws earlier.
“Support modules” that are not intended to be the main module of a program may
include a self-test of the module.
Even programs that interact with complex external interfaces may be tested when
the external interfaces are unavailable by using “fake” interfaces implemented
in Python.
The pydoc module can create HTML from the doc strings in your Python
source code.  An alternative for creating API documentation purely from
docstrings is epydoc.  Sphinx can also include docstring content.
For Unix variants there are several solutions.  It’s straightforward to do this
using curses, but curses is a fairly large module to learn."
How do I test a Python program or component?¶,"Python comes with two testing frameworks.  The doctest module finds
examples in the docstrings for a module and runs them, comparing the output with
the expected output given in the docstring.
The unittest module is a fancier testing framework modelled on Java and
Smalltalk testing frameworks.
To make testing easier, you should use good modular design in your program.
Your program should have almost all functionality
encapsulated in either functions or class methods – and this sometimes has the
surprising and delightful effect of making the program run faster (because local
variable accesses are faster than global accesses).  Furthermore the program
should avoid depending on mutating global variables, since this makes testing
much more difficult to do.
The “global main logic” of your program may be as simple as
at the bottom of the main module of your program.
Once your program is organized as a tractable collection of function and class
behaviours, you should write test functions that exercise the behaviours.  A
test suite that automates a sequence of tests can be associated with each module.
This sounds like a lot of work, but since Python is so terse and flexible it’s
surprisingly easy.  You can make coding much more pleasant and fun by writing
your test functions in parallel with the “production code”, since this makes it
easy to find bugs and even design flaws earlier.
“Support modules” that are not intended to be the main module of a program may
include a self-test of the module.
Even programs that interact with complex external interfaces may be tested when
the external interfaces are unavailable by using “fake” interfaces implemented
in Python."
How do I create documentation from doc strings?¶,"The pydoc module can create HTML from the doc strings in your Python
source code.  An alternative for creating API documentation purely from
docstrings is epydoc.  Sphinx can also include docstring content."
How do I get a single keypress at a time?¶,"For Unix variants there are several solutions.  It’s straightforward to do this
using curses, but curses is a fairly large module to learn."
How do I program using threads?¶,"Be sure to use the threading module and not the _thread module.
The threading module builds convenient abstractions on top of the
low-level primitives provided by the _thread module.
As soon as the main thread exits, all threads are killed.  Your main thread is
running too quickly, giving the threads no time to do any work.
A simple fix is to add a sleep to the end of the program that’s long enough for
all the threads to finish:
But now (on many platforms) the threads don’t run in parallel, but appear to run
sequentially, one at a time!  The reason is that the OS thread scheduler doesn’t
start a new thread until the previous thread is blocked.
A simple fix is to add a tiny sleep to the start of the run function:
Instead of trying to guess a good delay value for time.sleep(),
it’s better to use some kind of semaphore mechanism.  One idea is to use the
queue module to create a queue object, let each thread append a token to
the queue when it finishes, and let the main thread read as many tokens from the
queue as there are threads.
The easiest way is to use the concurrent.futures module,
especially the ThreadPoolExecutor class.
Or, if you want fine control over the dispatching algorithm, you can write
your own logic manually.  Use the queue module to create a queue
containing a list of jobs.  The Queue class maintains a
list of objects and has a .put(obj) method that adds items to the queue and
a .get() method to return them.  The class will take care of the locking
necessary to ensure that each job is handed out exactly once.
Here’s a trivial example:
When run, this will produce the following output:
Consult the module’s documentation for more details; the Queue
class provides a featureful interface.
A global interpreter lock (GIL) is used internally to ensure that only one
thread runs in the Python VM at a time.  In general, Python offers to switch
among threads only between bytecode instructions; how frequently it switches can
be set via sys.setswitchinterval().  Each bytecode instruction and
therefore all the C implementation code reached from each instruction is
therefore atomic from the point of view of a Python program.
In theory, this means an exact accounting requires an exact understanding of the
PVM bytecode implementation.  In practice, it means that operations on shared
variables of built-in data types (ints, lists, dicts, etc) that “look atomic”
really are.
For example, the following operations are all atomic (L, L1, L2 are lists, D,
D1, D2 are dicts, x, y are objects, i, j are ints):
These aren’t:
Operations that replace other objects may invoke those other objects’
__del__() method when their reference count reaches zero, and that can
affect things.  This is especially true for the mass updates to dictionaries and
lists.  When in doubt, use a mutex!
The global interpreter lock (GIL) is often seen as a hindrance to Python’s
deployment on high-end multiprocessor server machines, because a multi-threaded
Python program effectively only uses one CPU, due to the insistence that
(almost) all Python code can only run while the GIL is held.
Back in the days of Python 1.5, Greg Stein actually implemented a comprehensive
patch set (the “free threading” patches) that removed the GIL and replaced it
with fine-grained locking.  Adam Olsen recently did a similar experiment
in his python-safethread
project.  Unfortunately, both experiments exhibited a sharp drop in single-thread
performance (at least 30% slower), due to the amount of fine-grained locking
necessary to compensate for the removal of the GIL.
This doesn’t mean that you can’t make good use of Python on multi-CPU machines!
You just have to be creative with dividing the work up between multiple
processes rather than multiple threads.  The
ProcessPoolExecutor class in the new
concurrent.futures module provides an easy way of doing so; the
multiprocessing module provides a lower-level API in case you want
more control over dispatching of tasks.
Judicious use of C extensions will also help; if you use a C extension to
perform a time-consuming task, the extension can release the GIL while the
thread of execution is in the C code and allow other threads to get some work
done.  Some standard library modules such as zlib and hashlib
already do this.
It has been suggested that the GIL should be a per-interpreter-state lock rather
than truly global; interpreters then wouldn’t be able to share objects.
Unfortunately, this isn’t likely to happen either.  It would be a tremendous
amount of work, because many object implementations currently have global state.
For example, small integers and short strings are cached; these caches would
have to be moved to the interpreter state.  Other object types have their own
free list; these free lists would have to be moved to the interpreter state.
And so on.
And I doubt that it can even be done in finite time, because the same problem
exists for 3rd party extensions.  It is likely that 3rd party extensions are
being written at a faster rate than you can convert them to store all their
global state in the interpreter state.
And finally, once you have multiple interpreters not sharing any state, what
have you gained over running each interpreter in a separate process?"
How do I program using threads?¶,"Be sure to use the threading module and not the _thread module.
The threading module builds convenient abstractions on top of the
low-level primitives provided by the _thread module."
None of my threads seem to run: why?¶,"As soon as the main thread exits, all threads are killed.  Your main thread is
running too quickly, giving the threads no time to do any work.
A simple fix is to add a sleep to the end of the program that’s long enough for
all the threads to finish:
But now (on many platforms) the threads don’t run in parallel, but appear to run
sequentially, one at a time!  The reason is that the OS thread scheduler doesn’t
start a new thread until the previous thread is blocked.
A simple fix is to add a tiny sleep to the start of the run function:
Instead of trying to guess a good delay value for time.sleep(),
it’s better to use some kind of semaphore mechanism.  One idea is to use the
queue module to create a queue object, let each thread append a token to
the queue when it finishes, and let the main thread read as many tokens from the
queue as there are threads."
How do I parcel out work among a bunch of worker threads?¶,"The easiest way is to use the concurrent.futures module,
especially the ThreadPoolExecutor class.
Or, if you want fine control over the dispatching algorithm, you can write
your own logic manually.  Use the queue module to create a queue
containing a list of jobs.  The Queue class maintains a
list of objects and has a .put(obj) method that adds items to the queue and
a .get() method to return them.  The class will take care of the locking
necessary to ensure that each job is handed out exactly once.
Here’s a trivial example:
When run, this will produce the following output:
Consult the module’s documentation for more details; the Queue
class provides a featureful interface."
What kinds of global value mutation are thread-safe?¶,"A global interpreter lock (GIL) is used internally to ensure that only one
thread runs in the Python VM at a time.  In general, Python offers to switch
among threads only between bytecode instructions; how frequently it switches can
be set via sys.setswitchinterval().  Each bytecode instruction and
therefore all the C implementation code reached from each instruction is
therefore atomic from the point of view of a Python program.
In theory, this means an exact accounting requires an exact understanding of the
PVM bytecode implementation.  In practice, it means that operations on shared
variables of built-in data types (ints, lists, dicts, etc) that “look atomic”
really are.
For example, the following operations are all atomic (L, L1, L2 are lists, D,
D1, D2 are dicts, x, y are objects, i, j are ints):
These aren’t:
Operations that replace other objects may invoke those other objects’
__del__() method when their reference count reaches zero, and that can
affect things.  This is especially true for the mass updates to dictionaries and
lists.  When in doubt, use a mutex!"
Can’t we get rid of the Global Interpreter Lock?¶,"The global interpreter lock (GIL) is often seen as a hindrance to Python’s
deployment on high-end multiprocessor server machines, because a multi-threaded
Python program effectively only uses one CPU, due to the insistence that
(almost) all Python code can only run while the GIL is held.
Back in the days of Python 1.5, Greg Stein actually implemented a comprehensive
patch set (the “free threading” patches) that removed the GIL and replaced it
with fine-grained locking.  Adam Olsen recently did a similar experiment
in his python-safethread
project.  Unfortunately, both experiments exhibited a sharp drop in single-thread
performance (at least 30% slower), due to the amount of fine-grained locking
necessary to compensate for the removal of the GIL.
This doesn’t mean that you can’t make good use of Python on multi-CPU machines!
You just have to be creative with dividing the work up between multiple
processes rather than multiple threads.  The
ProcessPoolExecutor class in the new
concurrent.futures module provides an easy way of doing so; the
multiprocessing module provides a lower-level API in case you want
more control over dispatching of tasks.
Judicious use of C extensions will also help; if you use a C extension to
perform a time-consuming task, the extension can release the GIL while the
thread of execution is in the C code and allow other threads to get some work
done.  Some standard library modules such as zlib and hashlib
already do this.
It has been suggested that the GIL should be a per-interpreter-state lock rather
than truly global; interpreters then wouldn’t be able to share objects.
Unfortunately, this isn’t likely to happen either.  It would be a tremendous
amount of work, because many object implementations currently have global state.
For example, small integers and short strings are cached; these caches would
have to be moved to the interpreter state.  Other object types have their own
free list; these free lists would have to be moved to the interpreter state.
And so on.
And I doubt that it can even be done in finite time, because the same problem
exists for 3rd party extensions.  It is likely that 3rd party extensions are
being written at a faster rate than you can convert them to store all their
global state in the interpreter state.
And finally, once you have multiple interpreters not sharing any state, what
have you gained over running each interpreter in a separate process?"
How do I delete a file? (And other file questions…)¶,"Use os.remove(filename) or os.unlink(filename); for documentation, see
the os module.  The two functions are identical; unlink() is simply
the name of the Unix system call for this function.
To remove a directory, use os.rmdir(); use os.mkdir() to create one.
os.makedirs(path) will create any intermediate directories in path that
don’t exist. os.removedirs(path) will remove intermediate directories as
long as they’re empty; if you want to delete an entire directory tree and its
contents, use shutil.rmtree().
To rename a file, use os.rename(old_path, new_path).
To truncate a file, open it using f = open(filename, ""rb+""), and use
f.truncate(offset); offset defaults to the current seek position.  There’s
also os.ftruncate(fd, offset) for files opened with os.open(), where
fd is the file descriptor (a small integer).
The shutil module also contains a number of functions to work on files
including copyfile(), copytree(), and
rmtree().
The shutil module contains a copyfile() function.
Note that on Windows NTFS volumes, it does not copy
alternate data streams
nor resource forks
on macOS HFS+ volumes, though both are now rarely used.
It also doesn’t copy file permissions and metadata, though using
shutil.copy2() instead will preserve most (though not all) of it.
To read or write complex binary data formats, it’s best to use the struct
module.  It allows you to take a string containing binary data (usually numbers)
and convert it to Python objects; and vice versa.
For example, the following code reads two 2-byte integers and one 4-byte integer
in big-endian format from a file:
The ‘>’ in the format string forces big-endian data; the letter ‘h’ reads one
“short integer” (2 bytes), and ‘l’ reads one “long integer” (4 bytes) from the
string.
For data that is more regular (e.g. a homogeneous list of ints or floats),
you can also use the array module.
Note
To read and write binary data, it is mandatory to open the file in
binary mode (here, passing ""rb"" to open()).  If you use
""r"" instead (the default), the file will be open in text mode
and f.read() will return str objects rather than
bytes objects.
os.read() is a low-level function which takes a file descriptor, a small
integer representing the opened file.  os.popen() creates a high-level
file object, the same type returned by the built-in open() function.
Thus, to read n bytes from a pipe p created with os.popen(), you need to
use p.read(n).
For Win32, OSX, Linux, BSD, Jython, IronPython:
https://pypi.org/project/pyserial/
For Unix, see a Usenet post by Mitch Chapman:
https://groups.google.com/groups?selm=34A04430.CF9@ohioee.com
Python file objects are a high-level layer of
abstraction on low-level C file descriptors.
For most file objects you create in Python via the built-in open()
function, f.close() marks the Python file object as being closed from
Python’s point of view, and also arranges to close the underlying C file
descriptor.  This also happens automatically in f’s destructor, when
f becomes garbage.
But stdin, stdout and stderr are treated specially by Python, because of the
special status also given to them by C.  Running sys.stdout.close() marks
the Python-level file object as being closed, but does not close the
associated C file descriptor.
To close the underlying C file descriptor for one of these three, you should
first be sure that’s what you really want to do (e.g., you may confuse
extension modules trying to do I/O).  If it is, use os.close():
Or you can use the numeric constants 0, 1 and 2, respectively."
How do I delete a file? (And other file questions…)¶,"Use os.remove(filename) or os.unlink(filename); for documentation, see
the os module.  The two functions are identical; unlink() is simply
the name of the Unix system call for this function.
To remove a directory, use os.rmdir(); use os.mkdir() to create one.
os.makedirs(path) will create any intermediate directories in path that
don’t exist. os.removedirs(path) will remove intermediate directories as
long as they’re empty; if you want to delete an entire directory tree and its
contents, use shutil.rmtree().
To rename a file, use os.rename(old_path, new_path).
To truncate a file, open it using f = open(filename, ""rb+""), and use
f.truncate(offset); offset defaults to the current seek position.  There’s
also os.ftruncate(fd, offset) for files opened with os.open(), where
fd is the file descriptor (a small integer).
The shutil module also contains a number of functions to work on files
including copyfile(), copytree(), and
rmtree()."
How do I copy a file?¶,"The shutil module contains a copyfile() function.
Note that on Windows NTFS volumes, it does not copy
alternate data streams
nor resource forks
on macOS HFS+ volumes, though both are now rarely used.
It also doesn’t copy file permissions and metadata, though using
shutil.copy2() instead will preserve most (though not all) of it."
How do I read (or write) binary data?¶,"To read or write complex binary data formats, it’s best to use the struct
module.  It allows you to take a string containing binary data (usually numbers)
and convert it to Python objects; and vice versa.
For example, the following code reads two 2-byte integers and one 4-byte integer
in big-endian format from a file:
The ‘>’ in the format string forces big-endian data; the letter ‘h’ reads one
“short integer” (2 bytes), and ‘l’ reads one “long integer” (4 bytes) from the
string.
For data that is more regular (e.g. a homogeneous list of ints or floats),
you can also use the array module.
Note
To read and write binary data, it is mandatory to open the file in
binary mode (here, passing ""rb"" to open()).  If you use
""r"" instead (the default), the file will be open in text mode
and f.read() will return str objects rather than
bytes objects."
I can’t seem to use os.read() on a pipe created with os.popen(); why?¶,"os.read() is a low-level function which takes a file descriptor, a small
integer representing the opened file.  os.popen() creates a high-level
file object, the same type returned by the built-in open() function.
Thus, to read n bytes from a pipe p created with os.popen(), you need to
use p.read(n)."
How do I access the serial (RS232) port?¶,"For Win32, OSX, Linux, BSD, Jython, IronPython:
https://pypi.org/project/pyserial/
For Unix, see a Usenet post by Mitch Chapman:
https://groups.google.com/groups?selm=34A04430.CF9@ohioee.com"
"Why doesn’t closing sys.stdout (stdin, stderr) really close it?¶","Python file objects are a high-level layer of
abstraction on low-level C file descriptors.
For most file objects you create in Python via the built-in open()
function, f.close() marks the Python file object as being closed from
Python’s point of view, and also arranges to close the underlying C file
descriptor.  This also happens automatically in f’s destructor, when
f becomes garbage.
But stdin, stdout and stderr are treated specially by Python, because of the
special status also given to them by C.  Running sys.stdout.close() marks
the Python-level file object as being closed, but does not close the
associated C file descriptor.
To close the underlying C file descriptor for one of these three, you should
first be sure that’s what you really want to do (e.g., you may confuse
extension modules trying to do I/O).  If it is, use os.close():
Or you can use the numeric constants 0, 1 and 2, respectively."
What WWW tools are there for Python?¶,"See the chapters titled Internet Protocols and Support and Internet Data Handling in the Library
Reference Manual.  Python has many modules that will help you build server-side
and client-side web systems.
A summary of available frameworks is maintained by Paul Boddie at
https://wiki.python.org/moin/WebProgramming.
Cameron Laird maintains a useful set of pages about Python web technologies at
https://web.archive.org/web/20210224183619/http://phaseit.net/claird/comp.lang.python/web_python.
I would like to retrieve web pages that are the result of POSTing a form. Is
there existing code that would let me do this easily?
Yes. Here’s a simple example that uses urllib.request:
Note that in general for percent-encoded POST operations, query strings must be
quoted using urllib.parse.urlencode().  For example, to send
name=Guy Steele, Jr.:
See also
HOWTO Fetch Internet Resources Using The urllib Package for extensive examples.
You can find a collection of useful links on the Web Programming wiki page.
Use the standard library module smtplib.
Here’s a very simple interactive mail sender that uses it.  This method will
work on any host that supports an SMTP listener.
A Unix-only alternative uses sendmail.  The location of the sendmail program
varies between systems; sometimes it is /usr/lib/sendmail, sometimes
/usr/sbin/sendmail.  The sendmail manual page will help you out.  Here’s
some sample code:
The select module is commonly used to help with asynchronous I/O on
sockets.
To prevent the TCP connect from blocking, you can set the socket to non-blocking
mode.  Then when you do the connect(),
you will either connect immediately
(unlikely) or get an exception that contains the error number as .errno.
errno.EINPROGRESS indicates that the connection is in progress, but hasn’t
finished yet.  Different OSes will return different values, so you’re going to
have to check what’s returned on your system.
You can use the connect_ex() method
to avoid creating an exception.
It will just return the errno value.
To poll, you can call connect_ex() again later
– 0 or errno.EISCONN indicate that you’re connected – or you can pass this
socket to select.select() to check if it’s writable.
Note
The asyncio module provides a general purpose single-threaded and
concurrent asynchronous library, which can be used for writing non-blocking
network code.
The third-party Twisted library is
a popular and feature-rich alternative."
What WWW tools are there for Python?¶,"See the chapters titled Internet Protocols and Support and Internet Data Handling in the Library
Reference Manual.  Python has many modules that will help you build server-side
and client-side web systems.
A summary of available frameworks is maintained by Paul Boddie at
https://wiki.python.org/moin/WebProgramming.
Cameron Laird maintains a useful set of pages about Python web technologies at
https://web.archive.org/web/20210224183619/http://phaseit.net/claird/comp.lang.python/web_python."
How can I mimic CGI form submission (METHOD=POST)?¶,"I would like to retrieve web pages that are the result of POSTing a form. Is
there existing code that would let me do this easily?
Yes. Here’s a simple example that uses urllib.request:
Note that in general for percent-encoded POST operations, query strings must be
quoted using urllib.parse.urlencode().  For example, to send
name=Guy Steele, Jr.:
See also
HOWTO Fetch Internet Resources Using The urllib Package for extensive examples."
What module should I use to help with generating HTML?¶,You can find a collection of useful links on the Web Programming wiki page.
How do I send mail from a Python script?¶,"Use the standard library module smtplib.
Here’s a very simple interactive mail sender that uses it.  This method will
work on any host that supports an SMTP listener.
A Unix-only alternative uses sendmail.  The location of the sendmail program
varies between systems; sometimes it is /usr/lib/sendmail, sometimes
/usr/sbin/sendmail.  The sendmail manual page will help you out.  Here’s
some sample code:"
How do I avoid blocking in the connect() method of a socket?¶,"The select module is commonly used to help with asynchronous I/O on
sockets.
To prevent the TCP connect from blocking, you can set the socket to non-blocking
mode.  Then when you do the connect(),
you will either connect immediately
(unlikely) or get an exception that contains the error number as .errno.
errno.EINPROGRESS indicates that the connection is in progress, but hasn’t
finished yet.  Different OSes will return different values, so you’re going to
have to check what’s returned on your system.
You can use the connect_ex() method
to avoid creating an exception.
It will just return the errno value.
To poll, you can call connect_ex() again later
– 0 or errno.EISCONN indicate that you’re connected – or you can pass this
socket to select.select() to check if it’s writable.
Note
The asyncio module provides a general purpose single-threaded and
concurrent asynchronous library, which can be used for writing non-blocking
network code.
The third-party Twisted library is
a popular and feature-rich alternative."
Are there any interfaces to database packages in Python?¶,"Yes.
Interfaces to disk-based hashes such as DBM and GDBM are also included with standard Python.  There is also the
sqlite3 module, which provides a lightweight disk-based relational
database.
Support for most relational databases is available.  See the
DatabaseProgramming wiki page for details.
The pickle library module solves this in a very general way (though you
still can’t store things like open files, sockets or windows), and the
shelve library module uses pickle and (g)dbm to create persistent
mappings containing arbitrary Python objects."
Are there any interfaces to database packages in Python?¶,"Yes.
Interfaces to disk-based hashes such as DBM and GDBM are also included with standard Python.  There is also the
sqlite3 module, which provides a lightweight disk-based relational
database.
Support for most relational databases is available.  See the
DatabaseProgramming wiki page for details."
How do you implement persistent objects in Python?¶,"The pickle library module solves this in a very general way (though you
still can’t store things like open files, sockets or windows), and the
shelve library module uses pickle and (g)dbm to create persistent
mappings containing arbitrary Python objects."
How do I generate random numbers in Python?¶,"The standard module random implements a random number generator.  Usage
is simple:
This returns a random floating point number in the range [0, 1).
There are also many other specialized generators in this module, such as:
randrange(a, b) chooses an integer in the range [a, b).
uniform(a, b) chooses a floating point number in the range [a, b).
normalvariate(mean, sdev) samples the normal (Gaussian) distribution.
Some higher-level functions operate on sequences directly, such as:
choice(S) chooses a random element from a given sequence.
shuffle(L) shuffles a list in-place, i.e. permutes it randomly.
There’s also a Random class you can instantiate to create independent
multiple random number generators."
How do I generate random numbers in Python?¶,"The standard module random implements a random number generator.  Usage
is simple:
This returns a random floating point number in the range [0, 1).
There are also many other specialized generators in this module, such as:
randrange(a, b) chooses an integer in the range [a, b).
uniform(a, b) chooses a floating point number in the range [a, b).
normalvariate(mean, sdev) samples the normal (Gaussian) distribution.
Some higher-level functions operate on sequences directly, such as:
choice(S) chooses a random element from a given sequence.
shuffle(L) shuffles a list in-place, i.e. permutes it randomly.
There’s also a Random class you can instantiate to create independent
multiple random number generators."
How do I freeze Tkinter applications?¶,"Freeze is a tool to create stand-alone applications.  When freezing Tkinter
applications, the applications will not be truly stand-alone, as the application
will still need the Tcl and Tk libraries.
One solution is to ship the application with the Tcl and Tk libraries, and point
to them at run-time using the TCL_LIBRARY and TK_LIBRARY
environment variables.
To get truly stand-alone applications, the Tcl scripts that form the library
have to be integrated into the application as well. One tool supporting that is
SAM (stand-alone modules), which is part of the Tix distribution
(https://tix.sourceforge.net/).
Build Tix with SAM enabled, perform the appropriate call to
Tclsam_init(), etc. inside Python’s
Modules/tkappinit.c, and link with libtclsam and libtksam (you
might include the Tix libraries as well).
On platforms other than Windows, yes, and you don’t even
need threads!  But you’ll have to restructure your I/O
code a bit.  Tk has the equivalent of Xt’s XtAddInput() call, which allows you
to register a callback function which will be called from the Tk mainloop when
I/O is possible on a file descriptor.  See File Handlers.
An often-heard complaint is that event handlers bound
to events with the bind() method
don’t get handled even when the appropriate key is pressed.
The most common cause is that the widget to which the binding applies doesn’t
have “keyboard focus”.  Check out the Tk documentation for the focus command.
Usually a widget is given the keyboard focus by clicking in it (but not for
labels; see the takefocus option)."
How do I freeze Tkinter applications?¶,"Freeze is a tool to create stand-alone applications.  When freezing Tkinter
applications, the applications will not be truly stand-alone, as the application
will still need the Tcl and Tk libraries.
One solution is to ship the application with the Tcl and Tk libraries, and point
to them at run-time using the TCL_LIBRARY and TK_LIBRARY
environment variables.
To get truly stand-alone applications, the Tcl scripts that form the library
have to be integrated into the application as well. One tool supporting that is
SAM (stand-alone modules), which is part of the Tix distribution
(https://tix.sourceforge.net/).
Build Tix with SAM enabled, perform the appropriate call to
Tclsam_init(), etc. inside Python’s
Modules/tkappinit.c, and link with libtclsam and libtksam (you
might include the Tix libraries as well)."
Can I have Tk events handled while waiting for I/O?¶,"On platforms other than Windows, yes, and you don’t even
need threads!  But you’ll have to restructure your I/O
code a bit.  Tk has the equivalent of Xt’s XtAddInput() call, which allows you
to register a callback function which will be called from the Tk mainloop when
I/O is possible on a file descriptor.  See File Handlers."
I can’t get key bindings to work in Tkinter: why?¶,"An often-heard complaint is that event handlers bound
to events with the bind() method
don’t get handled even when the appropriate key is pressed.
The most common cause is that the widget to which the binding applies doesn’t
have “keyboard focus”.  Check out the Tk documentation for the focus command.
Usually a widget is given the keyboard focus by clicking in it (but not for
labels; see the takefocus option)."
